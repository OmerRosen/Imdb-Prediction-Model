{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_ZuJF2lhHRui4fu7P101KKc4AUqEmZvP",
      "authorship_tag": "ABX9TyOl5PQ7cFvwYHye7iTS38iB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmerRosen/Kaggle/blob/main/IMDB_2022_Hit_or_Flop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB 2022 - Hit or Flop"
      ],
      "metadata": {
        "id": "NQFvvfWPy8yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mission Statement"
      ],
      "metadata": {
        "id": "y0Rjw492zB7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data To Collect"
      ],
      "metadata": {
        "id": "YgCYDZTUzHKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search box page:\n",
        "* Movie Id\n",
        "* Movie Title\n",
        "* Movie year\n",
        "* Rating\n",
        "* MetaScore - Outcome\n",
        "* Description\n",
        "* Poster\n",
        "* Directore name + Link\n",
        "* Stars\n",
        "* Votes - Output\n",
        "* Genre"
      ],
      "metadata": {
        "id": "B67t6dw23MyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Movie Page data\n",
        "* Movie Length\n",
        "* Rank\n",
        "* Writer\n",
        "* Star #1\n",
        "* Star #2\n",
        "* Star #3\n",
        "* User eviews\n",
        "* Critic reviews\n",
        "* Number of photos posted\n",
        "* Storyline - Text\n",
        "* Tag line\n",
        "* Release Date - Month\n",
        "* Country of origin\n",
        "* Additional Lanaguages\n",
        "* Country of filming\n",
        "* Production companies\n",
        "* Budget\n",
        "* Opening Weekend Date\n",
        "* Gross US & Canada - Output\n",
        "* Opening weekend US & Canada - Output\n",
        "* Gross worldwide - Output\n",
        "* Color - Color\n",
        "* Color - Black&White\n",
        "* Sound mix - Dolby Digital\n",
        "* Sound mix - Dolby Atmos\n",
        "* Aspect ratio"
      ],
      "metadata": {
        "id": "57uP49Tx3Za2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Director Page:\n",
        "* Director Age\n",
        "* Is Top 500?\n",
        "* Director Gender (Based on bio)\n",
        "* Previous film count - As Director\n",
        "* Previous film count - As Writer\n",
        "* Previous film count - As As Producer\n",
        "* Director Publicity listing count"
      ],
      "metadata": {
        "id": "GFrFPrn13upo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Information Abount Cast:\n",
        "* Full list of cast and their profile links\n",
        "* Number of cast members\n",
        "* Produced by - Is top 500?\n",
        "* Music by - Is top 500?\n",
        "* Cinematography by  - Is top 500\n",
        "* Film Editing by   - Is top 500\n",
        "* Art Direction by  - Is top 500\n",
        "* Number of Production Management\n",
        "* Number of Art Department\n",
        "* Number of Sound Department\n",
        "* Number of Camera and Electrical Department\n",
        "* Number of Editorial Department\n",
        "* Number of Music Department\n",
        "* Number of Additional Crew"
      ],
      "metadata": {
        "id": "WJsID_wt3ujg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Actor Page\n",
        "* Is Top 5000?\n",
        "* Is Top 500?\n",
        "* Is Top 100 (aka - Has numberical rank)\n",
        "* Is Top 10 (aka - Has numberical rank)\n",
        "* Numerical Rank (Could be none)\n",
        "* Gender\n",
        "* Age\n",
        "* Oscar nominations \n",
        "* Birth country"
      ],
      "metadata": {
        "id": "nI2XH-eX3ubL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggragated data:\n",
        "* How many male stars\n",
        "* How many female stars\n",
        "* Avrage cast memeber age\n",
        "* Max/Min age of cast member\n",
        "* Number of unique birth countries of actors\n",
        "* Total number of Oscar numinatior for cast\n",
        "* Num cast members in top 5000\n",
        "* Num cast memebers in top 500\n",
        "* Num cast members in top 100\n",
        "* Num cast members in top 10"
      ],
      "metadata": {
        "id": "iJMm4uv_zRNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB Scraper"
      ],
      "metadata": {
        "id": "miwov1QlN7-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "OCmEiQzqGt7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "import json\n",
        "from time import sleep\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import traceback\n"
      ],
      "metadata": {
        "id": "SoeHu2EVOyw6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set main variables"
      ],
      "metadata": {
        "id": "KOSm1vl34Dgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.imdb.com\"\n",
        "base_folder_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project\"\n",
        "\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "minimum_votes = 10 # Minimum vote amount to coolect movie\n",
        "start_point = 1 # Start from movie #1-50\n",
        "\n",
        "movie_search_url = f\"{base_url}/search/title/?title_type=feature&release_date={start_date},{end_date}&num_votes={minimum_votes},&{start_point}anguages=en&start=1&ref_=adv_nxt\"\n",
        "movie_search_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9aLLijszN2JX",
        "outputId": "1796b4dd-ddef-4a7f-fb71-ada181d6993f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.imdb.com/search/title/?title_type=feature&release_date=2022-01-01,2022-12-31&num_votes=10,&1anguages=en&start=1&ref_=adv_nxt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
        "}\n",
        "\n",
        "list_of_50_movies = requests.get(f'{movie_search_url}', headers=headers, timeout=10)\n",
        "list_of_50_movies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPZnOmt7O4ZO",
        "outputId": "9824bf40-1a6c-4ddd-842d-ee47f2839558"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_50_movies_soup = BeautifulSoup(list_of_50_movies.text, 'html.parser').find_all('div',{'class':'lister-item mode-advanced'})\n"
      ],
      "metadata": {
        "id": "fXP7YHhYPEFJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_search_page = list_of_50_movies_soup[0]"
      ],
      "metadata": {
        "id": "TPVLgEErQ1ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Movie Box details"
      ],
      "metadata": {
        "id": "tOOcl9NX4Pye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_basic_details(movie_search_page):\n",
        "  search_box_info = {}\n",
        "  search_box_info['movie_name'] = movie_search_page.find('a')\n",
        "  search_box_info['movie_page_url'] = f\"{base_url}{movie_search_page.find('a')['href']}\"\n",
        "\n",
        "  try:\n",
        "    search_box_info['movie_place'] = None if not movie_search_page.find('span',{'class':'lister-item-index unbold text-primary'}) else movie_search_page.find('span',{'class':'lister-item-index unbold text-primary'}).text.replace('.','')\n",
        "    search_box_info['movie_id'] = None if not search_box_info['movie_page_url'] else search_box_info['movie_page_url'].split('/')[-2]\n",
        "    search_box_info['movie_name'] = None if not movie_search_page.find('a').find('img') else movie_search_page.find('a').find('img')['alt'].strip()\n",
        "    search_box_info['movie_thubmnail'] = None if not movie_search_page.find('a').find('img') else movie_search_page.find('a').find('img')['src']\n",
        "    search_box_info['movie_metascore'] = None if not movie_search_page.find('span', {'class': 'metascore'}) else movie_search_page.find('span', {'class': 'metascore'}).text.strip()\n",
        "    search_box_info['movie_description'] = None if not movie_search_page.find_all('p',{'class':'text-muted'}) else movie_search_page.find_all('p',{'class':'text-muted'})[1].text.strip()\n",
        "    search_box_info['runtime_min'] = None if not movie_search_page.find('span',{'class':'runtime'}) else movie_search_page.find('span',{'class':'runtime'}).text.split(' ')[0]\n",
        "\n",
        "    bottom_box_info = movie_search_page.find('p',{'class':'sort-num_votes-visible'}).find_all('span')\n",
        "    search_box_info['movie_vote_num'] = bottom_box_info[1]['data-value']\n",
        "\n",
        "    search_box_info['movie_rating'] = None if not movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'certificate'}) else movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'certificate'}).text.strip()\n",
        "    search_box_info['movie_genere'] = None if not movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'genre'}) else movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'genre'}).text.strip()\n",
        "\n",
        "    search_box_info['__SuccsefullyCollectBasicDetails'] = True;\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for movie: {search_box_info['movie_name']}. \\nUrl: {search_box_info['movie_page_url']}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    search_box_info['__SuccsefullyCollectBasicDetails'] = False;\n",
        "\n",
        "\n",
        "  return search_box_info"
      ],
      "metadata": {
        "id": "ma8O2qtIaahp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_search_page = list_of_50_movies_soup[1]\n",
        "search_box_info = get_basic_details(movie_search_page)\n",
        "search_box_info\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSPtu7JccDLW",
        "outputId": "6f830f0a-2e81-4081-a2c9-3916474bedde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie_name': 'Everything Everywhere All at Once',\n",
              " 'movie_page_url': 'https://www.imdb.com/title/tt6710474/?ref_=adv_li_i',\n",
              " 'movie_place': '2',\n",
              " 'movie_id': 'tt6710474',\n",
              " 'movie_thubmnail': 'https://m.media-amazon.com/images/S/sash/4FyxwxECzL-U1J8.png',\n",
              " 'movie_metascore': '81',\n",
              " 'movie_description': 'A middle-aged Chinese immigrant is swept up into an insane adventure in which she alone can save existence by exploring other universes and connecting with the lives she could have led.',\n",
              " 'runtime_min': '139',\n",
              " 'movie_vote_num': '428561',\n",
              " 'movie_rating': 'R',\n",
              " 'movie_genere': 'Action, Adventure, Comedy',\n",
              " '__SuccsefullyCollectBasicDetails': True}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_movie_url = \"https://www.imdb.com/title/tt14174168/?ref_=adv_li_i\"#search_box_info['movie_page_url']\n",
        "movie_main_page = requests.get(search_box_info['movie_page_url'], headers=headers)\n",
        "movie_main_page_soup = BeautifulSoup(movie_main_page.text, 'html.parser')"
      ],
      "metadata": {
        "id": "HcDJ2qcBlNUM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Extract Movie Artists"
      ],
      "metadata": {
        "id": "Ui9hyYvhG_R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist(artist_type, movie_main_page_soup):\n",
        "\n",
        "  item_dict = {}\n",
        "\n",
        "  search_result = movie_main_page_soup.find(string=f\"{artist_type}s\") if movie_main_page_soup.find(string=artist_type) is None else movie_main_page_soup.find(string=artist_type)\n",
        "  search_item_list = []\n",
        "  if search_result!=None:\n",
        "    search_item_list = search_result.find_parent().find_next_sibling().find_all('a')\n",
        "  \n",
        "  item_dict[f\"{artist_type}_count\"] = len(search_item_list)\n",
        "\n",
        "  for i,item in enumerate(search_item_list):\n",
        "    artisc_name = item.text.strip()\n",
        "    artisc_url = item['href']\n",
        "    artist_id = artisc_url.split('/')[2]\n",
        "    item_dict[f\"{artist_type}_{i+1}_name\"] = artisc_name\n",
        "    #item_dict[f\"{artist_type}_{i+1}_url\"] = artisc_url\n",
        "    item_dict[f\"{artist_type}_{i+1}_imdb_id\"] = artist_id\n",
        "\n",
        "  return item_dict\n",
        "\n",
        "print(extract_artist(\"Director\", movie_main_page_soup))\n",
        "print(extract_artist(\"Writer\", movie_main_page_soup))\n",
        "print(extract_artist(\"Star\", movie_main_page_soup))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLMezvBZ8q3N",
        "outputId": "643e9fa5-d566-4d92-9a78-0119fdb42245"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Director_count': 2, 'Director_1_name': 'Daniel Kwan', 'Director_1_imdb_id': 'nm3453283', 'Director_2_name': 'Daniel Scheinert', 'Director_2_imdb_id': 'nm3215397'}\n",
            "{'Writer_count': 2, 'Writer_1_name': 'Daniel Kwan', 'Writer_1_imdb_id': 'nm3453283', 'Writer_2_name': 'Daniel Scheinert', 'Writer_2_imdb_id': 'nm3215397'}\n",
            "{'Star_count': 3, 'Star_1_name': 'Michelle Yeoh', 'Star_1_imdb_id': 'nm0000706', 'Star_2_name': 'Stephanie Hsu', 'Star_2_imdb_id': 'nm3513533', 'Star_3_name': 'Jamie Lee Curtis', 'Star_3_imdb_id': 'nm0000130'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Perform Currency Conversion"
      ],
      "metadata": {
        "id": "t8ANYROE8boz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "currency_codes = {\n",
        "    \"$\":\"USD\",\n",
        "    \"€\":\"EUR\",\n",
        "    \"£\":\"GBP\",\n",
        "    \"₹\":\"INR\",\n",
        "    \"â‚¬\": \"EUR\",\n",
        "    \"â‚¹\": \"INR\",\n",
        "    \"CA$\": \"CAD\",\n",
        "    \"NOKÂ\": \"NOK\",\n",
        "    \"Â£\": \"GBP\",\n",
        "    \"CHF\": \"CHF\",\n",
        "    \"Â¥\": \"JPY\",\n",
        "    \"PKR\": \"PKR\",\n",
        "    \"A$\": \"AUD\",\n",
        "    \"CZK\": \"CZK\",\n",
        "    \"RUR\": \"RUB\",\n",
        "    \"NZ$\": \"NZD\",\n",
        "    \"MYR\": \"MYR\",\n",
        "    \"NGN\": \"NGN\",\n",
        "    \"NOK\":\"NOK\",\n",
        "    \"A$\":\"AUD\",\n",
        "    \"â‚¬\":\"EUR\",\n",
        "    \"â‚¹\":\"INR\",\n",
        "    \"Â£\":\"GBP\",\n",
        "    \"CA$\":\"CAD\",\n",
        "    \"CHFÂ \":\"CHF\",\n",
        "    \"MYRÂ \":\"MYR\",\n",
        "    \"NGNÂ \":\"NGN\",\n",
        "    \"NOKÂ \":\"NOK\",\n",
        "    \"NZ$\":\"NZD\",\n",
        "    \"PKRÂ \":\"PKR\",\n",
        "    \"RURÂ \":\"RUB\",\n",
        "    \"IRR \":\"IRR\"\n",
        "}\n",
        "\n",
        "\n",
        "currency_conversion_values = {}\n"
      ],
      "metadata": {
        "id": "xTQyDlNNRMTT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_currency_symbol(s):\n",
        "    match = re.search(r\"[^\\d]+\", s)\n",
        "    if match:\n",
        "        return match.group(0).strip()\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "Ffkj0oe7Vmee"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_currency_code(amount_string):\n",
        "  currency_symbol = extract_currency_symbol(amount_string)\n",
        "  if currency_symbol in currency_codes:\n",
        "      return currency_codes[currency_symbol]\n",
        "  else:\n",
        "    print(f\"Could not find a value for: {currency_symbol} in {amount_string}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "LFYkrlxHWeMw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_numerical_value(string):\n",
        "    # Remove all non-numeric characters from the string\n",
        "    numerical_string = re.sub(r\"[^\\d.]+\", \"\", string)\n",
        "    # Convert the string to a float and return it\n",
        "    return float(numerical_string)"
      ],
      "metadata": {
        "id": "q_2ySIZiXwK8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(f'{base_folder_path}/openexchangerates.txt', 'r') as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "api_key\n",
        "\n",
        "def convert_string_amount_to_usd(amount):\n",
        "\n",
        "  # get the currency code and amount value\n",
        "  currency_code = get_currency_code(amount)\n",
        "  original_amount = extract_numerical_value(amount)\n",
        "  usd_amount = None\n",
        "\n",
        "  if currency_code==None:\n",
        "    usd_amount=None\n",
        "  elif currency_code!=\"USD\":\n",
        "  \n",
        "    if currency_code in currency_conversion_values:\n",
        "      exchange_rate = currency_conversion_values[currency_code]\n",
        "    else:\n",
        "      # make API request to get exchange rate for the currency code\n",
        "      url = f\"https://openexchangerates.org/api/latest.json?app_id={api_key}&symbols={currency_code}\"\n",
        "      print(amount,currency_code,original_amount,url)\n",
        "      response = requests.get(url)\n",
        "      print(response)\n",
        "      # parse the exchange rate from the API response\n",
        "      exchange_rate = response.json()[\"rates\"][currency_code]\n",
        "      \n",
        "      currency_conversion_values[currency_code] = exchange_rate\n",
        "      \n",
        "      # calculate the USD equivalent amount\n",
        "      usd_amount = round(original_amount / exchange_rate)\n",
        "      \n",
        "      print(f\"{amount} {currency_code} = {usd_amount} USD\")\n",
        "  else:\n",
        "    usd_amount = original_amount\n",
        "\n",
        "  return usd_amount,original_amount,currency_code\n",
        "\n",
        "\n",
        "\n",
        "convert_string_amount_to_usd(\"CA$15,000\")\n",
        "convert_string_amount_to_usd(\"NOKÂ 80,200,000\")\n",
        "convert_string_amount_to_usd(\"NOKÂ 20,000,000\")\n",
        "convert_string_amount_to_usd(\"â‚¹3,500,000,000\")\n",
        "currency_conversion_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY3pGk9-N4t9",
        "outputId": "adb18e4f-6f1f-44ab-9210-d7b7ea0ee2ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CA$15,000 CAD 15000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=CAD\n",
            "<Response [200]>\n",
            "CA$15,000 CAD = 11199 USD\n",
            "NOKÂ 80,200,000 NOK 80200000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=NOK\n",
            "<Response [200]>\n",
            "NOKÂ 80,200,000 NOK = 7647206 USD\n",
            "â‚¹3,500,000,000 INR 3500000000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=INR\n",
            "<Response [200]>\n",
            "â‚¹3,500,000,000 INR = 42639505 USD\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CAD': 1.339457, 'NOK': 10.487491, 'INR': 82.083505}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Movie Cast List and count"
      ],
      "metadata": {
        "id": "tNiDUkqFAa-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cast_list(cast_page_url):\n",
        "\n",
        "  cast_counts = {'cast_count_total':0}\n",
        "\n",
        "  cast_page = requests.get(cast_page_url, headers=headers)\n",
        "  cast_page_soup = BeautifulSoup(cast_page.text, 'html.parser')   \n",
        "\n",
        "  cast_groups = cast_page_soup.find_all('h4')\n",
        "\n",
        "  for cast_group in cast_groups:\n",
        "    try:\n",
        "      group_name = cast_group['id']\n",
        "      #print(group_name)\n",
        "      group_list = cast_group.find_next_sibling()\n",
        "      group_count = 0\n",
        "      if group_list is not None:\n",
        "        group_list = group_list.findAll('tr')\n",
        "        group_count = len(group_list)\n",
        "      cast_counts[f\"cast_count_{group_name}\"] = group_count\n",
        "      cast_counts['cast_count_total'] += group_count\n",
        "    except Exception as ex:\n",
        "      pass\n",
        "  return cast_counts\n",
        "\n",
        "get_cast_list(\"https://www.imdb.com/title/tt18375618/fullcredits\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_2zu-lf7BAy",
        "outputId": "c4ff4369-0850-409a-ba90-588cceaeaa65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cast_count_total': 13,\n",
              " 'cast_count_director': 1,\n",
              " 'cast_count_writer': 1,\n",
              " 'cast_count_cast': 6,\n",
              " 'cast_count_producer': 2,\n",
              " 'cast_count_cinematographer': 1,\n",
              " 'cast_count_editor': 1,\n",
              " 'cast_count_location_management': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Movie Page Extanded Details"
      ],
      "metadata": {
        "id": "tQaXU0Ib4V6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_extended_datails(movie_page_url, movie_name):\n",
        "  movie_page_dict = {}\n",
        "\n",
        "  try:\n",
        "\n",
        "    movie_main_page = requests.get(movie_page_url, headers=headers)\n",
        "    movie_main_page_soup = BeautifulSoup(movie_main_page.text, 'html.parser')   \n",
        "\n",
        "    year_rating = movie_main_page_soup.find('ul',{\"class\":\"ipc-inline-list ipc-inline-list--show-dividers sc-afe43def-4 kdXikI baseAlt\"}).find_all('a')\n",
        "\n",
        "    movie_page_dict['movie_year'] = year_rating[0].text if len(year_rating)>0 else None\n",
        "    movie_page_dict['movie_rating'] = year_rating[1].text if len(year_rating)>1 else None\n",
        "\n",
        "    director_dict = extract_artist(\"Director\", movie_main_page_soup)\n",
        "    if director_dict[f\"Director_count\"] == 0:\n",
        "      print(f\"No Director found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(director_dict)\n",
        "\n",
        "    writer_dict = extract_artist(\"Writer\", movie_main_page_soup)\n",
        "    if writer_dict[f\"Writer_count\"] == 0:\n",
        "      print(f\"No Writer found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(writer_dict)\n",
        "\n",
        "    star_dict = extract_artist(\"Star\", movie_main_page_soup)\n",
        "    if star_dict[f\"Star_count\"] == 0:\n",
        "      print(f\"No Star found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(star_dict)\n",
        "\n",
        "    review_scores = movie_main_page_soup.find_all('span',{'class':'score'})\n",
        "    movie_page_dict['user_reviews_count'] = review_scores[0].text if len(review_scores)>0 else None\n",
        "    movie_page_dict['critic_reviews_count'] = review_scores[1].text if len(review_scores)>1 else None\n",
        "\n",
        "    movie_page_dict['release_date'] = movie_main_page_soup.find('a',{'class':'ipc-metadata-list-item__label ipc-metadata-list-item__label--link'}, string=\"Release date\").find_parent().find('a',{'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'}).text.split('(')[0].strip()\n",
        "    movie_page_dict['release_date']\n",
        "\n",
        "    movie_page_dict['budget'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Budget\")\n",
        "    if (movie_page_dict['budget']!=None):\n",
        "      movie_page_dict['budget'] = movie_page_dict['budget'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "\n",
        "      usd_amount,original_amount,currency_code = convert_string_amount_to_usd(movie_page_dict['budget'])\n",
        "      movie_page_dict['budget_usd'] = usd_amount\n",
        "      movie_page_dict['budget_currency'] = currency_code\n",
        "\n",
        "    movie_page_dict['gross_worldwide'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Gross worldwide\")\n",
        "    if (movie_page_dict['gross_worldwide']!=None):\n",
        "      movie_page_dict['gross_worldwide'] = movie_page_dict['gross_worldwide'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['gross_worldwide'], _, _ = convert_string_amount_to_usd(movie_page_dict['gross_worldwide'])\n",
        "\n",
        "    movie_page_dict['gross_us_canada'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Gross US & Canada\")\n",
        "    if (movie_page_dict['gross_us_canada']!=None):\n",
        "      movie_page_dict['gross_us_canada'] = movie_page_dict['gross_us_canada'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['gross_us_canada'], _, _ = convert_string_amount_to_usd(movie_page_dict['gross_us_canada'])\n",
        "\n",
        "    movie_page_dict['opening_weekend_us_canada'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Opening weekend US & Canada\")\n",
        "    if (movie_page_dict['opening_weekend_us_canada']!=None):\n",
        "      movie_page_dict['opening_weekend_us_canada'] = movie_page_dict['opening_weekend_us_canada'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['opening_weekend_us_canada'], _, _ = convert_string_amount_to_usd(movie_page_dict['opening_weekend_us_canada'])\n",
        "\n",
        "    movie_page_dict['origin_country'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Country of origin\")\n",
        "    if (movie_page_dict['origin_country']!=None):\n",
        "      movie_page_dict['origin_country'] = movie_page_dict['origin_country'].find_next_sibling().find('a').text.split('(')[0].strip()\n",
        "\n",
        "    languages = movie_main_page_soup.find('span',string=\"Language\") if movie_main_page_soup.find('span',string=\"Languages\") is None else movie_main_page_soup.find('span',string=\"Languages\")\n",
        "    languages = [] if not languages else languages.find_next_sibling().find_all('a')\n",
        "    movie_page_dict['languages'] = \",\".join([language.text for language in languages])\n",
        "\n",
        "    movie_page_dict['__SuccsefullyCollectExtandedDetails'] = True;\n",
        "\n",
        "    ## Collect cast count for movie:\n",
        "    movie_id = movie_page_url.split('/')[-2]\n",
        "    cast_page_url = f\"https://www.imdb.com/title/{movie_id}/fullcredits\"\n",
        "    cast_list = get_cast_list(cast_page_url)\n",
        "    movie_page_dict.update(cast_list)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for movie: {movie_name}. \\nUrl: {movie_page_url}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    movie_page_dict['__SuccsefullyCollectExtandedDetails'] = False;\n",
        "\n",
        "  return movie_page_dict\n",
        "\n",
        "\n",
        "get_extended_datails(search_box_info['movie_page_url'],search_box_info['movie_name'])"
      ],
      "metadata": {
        "id": "XH4irJSLculw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(search_box_info['movie_page_url'],search_box_info['movie_name'])\n",
        "# cast_url = movie_main_page_soup.find('a',{'class':'ipc-metadata-list-item__label ipc-metadata-list-item__label--link'})['href']\n",
        "# cast_url = f\"{base_url}{cast_url}\"\n",
        "# cast_url"
      ],
      "metadata": {
        "id": "vEii_FS-9zTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic parameters:\n",
        "\n",
        "def get_50_movie_batch(start_point, minimum_votes = 20, start_date = \"2022-01-01\", end_date = \"2022-12-31\"):\n",
        "  movie_search_url_50_batch = f\"{base_url}/search/title/?title_type=feature&release_date={start_date},{end_date}&num_votes={minimum_votes},&user_rating=1.0,10.0&countries=us&languages=en&start={start_point}&ref_=adv_nxt\"\n",
        "  #print(f\"Start point: {start_point}. search url: {movie_search_url_50_batch}\")\n",
        "  search_page = requests.get(f'{movie_search_url_50_batch}', headers=headers, timeout=10)\n",
        "  search_page_soup = BeautifulSoup(search_page.text, 'html.parser')\n",
        "  list_of_50_movies_soup = search_page_soup.find_all('div',{'class':'lister-item mode-advanced'})\n",
        "\n",
        "  max_num_of_results = search_page_soup.find('div',{'class':'desc'}).find('span').text.split(' ')[2].replace(\",\", \"\")\n",
        "  max_num_of_results = int(max_num_of_results)\n",
        "\n",
        "  #print(f\"max_num_of_results: {max_num_of_results}\")\n",
        "  return(list_of_50_movies_soup,max_num_of_results)\n",
        "\n",
        "list_of_50_movies_soup,max_num_of_results = get_50_movie_batch(start_point = 1, minimum_votes = 20, start_date = \"2022-01-01\", end_date = \"2022-12-31\")"
      ],
      "metadata": {
        "id": "RYjnulARhT5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters:\n",
        "base_url = \"https://www.imdb.com\"\n",
        "\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "minimum_votes = 20 # Minimum vote amount to coolect movie\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"}"
      ],
      "metadata": {
        "id": "NZCEUr1_HFkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/total_movie_dataset.csv\"\n",
        "if os.path.exists(movie_dataset_path):\n",
        "  movie_df = pd.read_csv(movie_dataset_path)\n",
        "  total_movie_dataset = movie_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  total_movie_dataset = {}\n",
        "  movie_df = pd.DataFrame(total_movie_dataset)\n",
        "\n",
        "print(f\"total_movie_dataset contains {len(total_movie_dataset)} records\")\n",
        "movie_df.head(3)"
      ],
      "metadata": {
        "id": "1HHWreXyWqRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Collecting movies from IMDB"
      ],
      "metadata": {
        "id": "TxMZRWuGG3SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_point = 1 # Start from movie #1-50\n",
        "\n",
        "basic_data_collected = 0\n",
        "basic_data_skipped = 0\n",
        "extended_data_collected = 0\n",
        "extended_data_skipped = 0\n",
        "\n",
        "count = 1\n",
        "while start_point < max_num_of_results-50:\n",
        "\n",
        "  list_of_50_movies_soup,_ = get_50_movie_batch(start_point = start_point, minimum_votes = 20, start_date = \"2022-01-01\", end_date = \"2022-12-31\")\n",
        "\n",
        "  for i,movie in enumerate(list_of_50_movies_soup):\n",
        "    movie_data = {'__SuccsefullyCollectBasicDetails':False, '__SuccsefullyCollectExtandedDetails':False}\n",
        "\n",
        "    basic_data = get_basic_details(movie)\n",
        "    movie_id = basic_data['movie_id']\n",
        "\n",
        "    try:\n",
        "      if movie_id in total_movie_dataset.keys():\n",
        "        movie_data = total_movie_dataset[movie_id]\n",
        "\n",
        "      if movie_data['__SuccsefullyCollectBasicDetails']==True:\n",
        "        basic_data_skipped += 1\n",
        "      else:\n",
        "        basic_data_collected += 1\n",
        "        movie_data.update(basic_data)\n",
        "\n",
        "      if movie_data['__SuccsefullyCollectExtandedDetails']==True:\n",
        "        extended_data_skipped += 1\n",
        "      else:\n",
        "        extended_data_collected += 1\n",
        "        extended_data = get_extended_datails(basic_data['movie_page_url'],basic_data['movie_name'])\n",
        "        movie_data.update(extended_data)\n",
        "\n",
        "        sleep(0.1)\n",
        "    except Exception as e:\n",
        "      print(f\"Failed running cursor for movie: {movie_id}. \\nUrl: {basic_data['movie_page_url']}.\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "    total_movie_dataset[movie_id] = movie_data\n",
        "    count+= 1\n",
        "\n",
        "    if (count%200 == 0):\n",
        "      print(f\"\\nRun number: {count}. basic_data_collected: {basic_data_collected}. extended_data_collected: {extended_data_collected}. basic_data_skipped: {basic_data_skipped}. extended_data_skipped: {extended_data_skipped}\")\n",
        "\n",
        "\n",
        "  movie_dataset = pd.DataFrame(total_movie_dataset).T\n",
        "  movie_dataset.to_csv(movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "\n",
        "  start_point += 50\n",
        "\n",
        "print(f\"\\nRun number: {count}. \\nbasic_data_collected: {basic_data_collected}. \\nextended_data_collected: {extended_data_collected}. \\nbasic_data_skipped: {basic_data_skipped}. \\nextended_data_skipped: {extended_data_skipped}\\n\")"
      ],
      "metadata": {
        "id": "9ASPUpIMHT2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.DataFrame(total_movie_dataset).T\n",
        "movie_dataset.to_csv(movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "\n",
        "movie_dataset.head(5)"
      ],
      "metadata": {
        "id": "1zPMKZlwevQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set actor variables"
      ],
      "metadata": {
        "id": "gmEs7UDA4sFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "import json\n",
        "from time import sleep\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import traceback"
      ],
      "metadata": {
        "id": "InfuPc6m64Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.read_csv('/content/drive/My Drive/Harvard HW/Course 4 - Final Project/total_movie_dataset.csv')\n",
        "movie_dataset.head(5)"
      ],
      "metadata": {
        "id": "mDjtqHinj9cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Assume Gender"
      ],
      "metadata": {
        "id": "T0RJfRFee_ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assume_gender(artist_bio):\n",
        "  # Define the pronouns associated with each gender\n",
        "  male_pronouns = [\"he\", \"him\", \"his\", \"himself\",\"guy\",\"man\"]\n",
        "  female_pronouns = [\"she\", \"her\", \"hers\", \"herself\",\"girl\",\"woman\"]\n",
        "  nonbinary_pronouns = [\"themselves\",\"queer\",\"binary\",\"nonbinary\",\"non-binary\"]\n",
        "\n",
        "  # Count the number of male and female pronouns in the bio\n",
        "  prnoun_count = {'Male':0, \"Female\":0, \"NonBinary\":0}\n",
        "\n",
        "  for word in artist_bio.lower().split():\n",
        "      if word in male_pronouns:\n",
        "          prnoun_count[\"Male\"] += 1\n",
        "      elif word in female_pronouns:\n",
        "          prnoun_count[\"Female\"] += 1\n",
        "      elif word in nonbinary_pronouns:\n",
        "          prnoun_count[\"NonBinary\"] += 1\n",
        "\n",
        "  # Determine the actor's gender based on the pronoun count\n",
        "  sorted_d = {k: v for k, v in sorted(prnoun_count.items(), key=lambda item: item[1], reverse=True)}\n",
        "  Gender = next(iter(sorted_d))\n",
        "\n",
        "  if prnoun_count[Gender] == 0: # If no prnoune was found\n",
        "    Gender = \"Unknown\"\n",
        "\n",
        "  return Gender\n",
        "\n",
        "# Extract the bio text\n",
        "bio_text = \"\"\"Andy Samberg was born in Berkeley, California, to Marjorie (Marrow), a teacher, and Joe Samberg, a photographer. With Jorma Taccone and Akiva Schaffer, Samberg is one of three Los Angeles, California-based writer-performer-filmmakers--all childhood friends--dubbed The Lonely Island, whose short films were showcased on the popular untelevised television network show and website. Some of their popular shorts included The O.C. (2003) parody \"The 'Bu\" and their full-length pilot, \"Awesometown.\" They met Jimmy Fallon while writing for 2004 MTV Video Music Awards (2004), who then suggested that they audition for Saturday Night Live (1975). Andy was then cast as a featured performer, and Samberg's Lonely Island cohorts Jorma and Akiva were hired as writers for the show. The group's most notable contributions include The Lonely Island: Lazy Sunday (2005), The Lonely Island feat. Justin Timberlake: Dick in a Box (2006), and The Lonely Island Feat. T-Pain: I'm on a Boat (2009).\n",
        "\n",
        "Near the end of his first season of SNL, Andy started filming the lead role in the film Hot Rod (2007), the first major motion picture by the Lonely Island team, with the production support of Lorne Michaels.\n",
        "\n",
        "In 2012, after seven years of working on SNL, Samberg resigned from the show. He was originally not looking to join a television series as a regular cast member, but after seeing the script for Brooklyn Nine-Nine (2013), he couldn't pass it up. Andy plays Jake Peralta, the best detective in Brooklyn's 99th police precinct, who also happens to be the most immature. In 2013 Samberg received the Golden Globe for Best Actor - Television Series Musical or Comedy for his performance.\n",
        "\n",
        "In 2016, Andy starred in the pop music mockumentary Popstar: Never Stop Never Stopping (2016). Taccone and Schaffer co-starred in and co-directed the film.\n",
        "\n",
        "Samberg married singer-songwriter Joanna Newsom on 21 September, 2013, in Big Sur, California. In August 2017, they announced the birth of their baby daughter.\n",
        "\"\"\"\n",
        "assume_gender(bio_text)"
      ],
      "metadata": {
        "id": "muJrvn4spKx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from dateutil import parser\n",
        "\n",
        "def extract_artist_age(date_string):\n",
        "  try:\n",
        "    # Parse the date string into a datetime object\n",
        "    date_obj = parser.parse(date_string)\n",
        "    # Check if the date is in the future, if so - Reduce 100 years\n",
        "    if date_obj.year > datetime.now().year:\n",
        "      date_obj = date_obj.replace(year=date_obj.year - 100)\n",
        "    #print(date_obj)\n",
        "    # Calculate the difference between the current date and the date of birth\n",
        "    age = relativedelta(datetime.now(), date_obj).years\n",
        "    # Return the age as an integer\n",
        "    return age\n",
        "  except:\n",
        "    #print(f\"Cannot extract age from value: {date_string}\")\n",
        "    return None\n",
        "\n",
        "print(extract_artist_age(\"11/25/1990\"))\n",
        "print(extract_artist_age(\"16-Apr-02\"))\n",
        "print(extract_artist_age(\"\"))"
      ],
      "metadata": {
        "id": "ocSn8KhHmzKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Collect Rank"
      ],
      "metadata": {
        "id": "jiX7kUTS42-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_artist_rank(artist_page_soup,artist_dict):\n",
        "  artist_rank = artist_page_soup.find('span',{'class':'sc-d462a8ef-6 hOuQwM starmeter-current-rank'}).text.strip()\n",
        "\n",
        "  artist_dict['artist_rank'] = artist_rank\n",
        "  artist_dict['Is_5000'] = False\n",
        "  artist_dict['Is_500'] = False\n",
        "  artist_dict['Is_100'] = False\n",
        "  artist_dict['Is_10'] = False\n",
        "\n",
        "  if artist_rank.lower()!=\"see rank\":\n",
        "    if artist_rank==\"Top 5,000\":\n",
        "      artist_dict['Is_5000'] = True\n",
        "    elif artist_rank==\"Top 500\":\n",
        "      artist_dict['Is_500'] = True\n",
        "      artist_dict['Is_5000'] = True\n",
        "    else:\n",
        "      try:\n",
        "        rank = int(artist_rank)   # Convert the string to an integer\n",
        "        if rank <= 100:           # Check if the rank is within the top 100\n",
        "          artist_dict['Is_100'] = True\n",
        "          artist_dict['Is_500'] = True\n",
        "          artist_dict['Is_5000'] = True\n",
        "        if rank <= 10: \n",
        "          artist_dict['Is_10'] = True\n",
        "      except ValueError:\n",
        "        print(f\"Could not interpret value {artist_rank} for artist: {artist_dict['artist_imdb_id']}. Url: {artist_dict['artist_url']}\")\n",
        "\n",
        "artist_imdb_id = \"nm14727093\"\n",
        "artist_page = requests.get(f\"https://www.imdb.com/name/{artist_imdb_id}/\", headers=headers)\n",
        "artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "artist_dict = {}\n",
        "artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "artist_dict['artist_type'] = \"Director\"\n",
        "artist_dict['artist_url'] = artist_page\n",
        "collect_artist_rank(artist_page_soup,artist_dict)"
      ],
      "metadata": {
        "id": "-7vuUgpgqjXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Artist awards"
      ],
      "metadata": {
        "id": "pbBKnsyCFirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_awards_info(awards_str):\n",
        "    wins = 0\n",
        "    nominations = 0\n",
        "    if awards_str:\n",
        "      parts = awards_str.split()\n",
        "      if \"wins\" in parts:\n",
        "          wins = int(parts[parts.index(\"wins\")-1])\n",
        "      elif \"win\" in parts:\n",
        "          wins = int(parts[parts.index(\"win\")-1])\n",
        "      if \"nominations\" in parts:\n",
        "          nominations = int(parts[parts.index(\"nominations\")-1])\n",
        "      elif \"nomination\" in parts:\n",
        "          nominations = int(parts[parts.index(\"nomination\")-1])\n",
        "    return (wins, nominations)\n",
        "\n",
        "print(get_awards_info(\"6 wins & 16 nominations total\"))\n",
        "print(get_awards_info(\"1 win & 1 nomination total\"))\n",
        "print(get_awards_info(\"6 wins total\"))\n",
        "print(get_awards_info(\"16 nominations total\"))\n",
        "print(get_awards_info('1 win & 3 nominations'))\n",
        "print(get_awards_info(\"\"))\n",
        "print(get_awards_info(None))"
      ],
      "metadata": {
        "id": "JAwyoxUHRNbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_artist_awards(artist_page_soup):\n",
        "  awards_dict = {}\n",
        "\n",
        "  awards = artist_page_soup.find('li',{'data-testid':'award_information'})\n",
        "  awards_prestige_wins = 0\n",
        "  awards_prestige_nominations = 0\n",
        "  awards_other_won = 0\n",
        "  awards_other_nominations = 0\n",
        "  \n",
        "  if awards!=None:\n",
        "\n",
        "    # Find prestige awards (Oscars, BEFTA, ect.)\n",
        "    prestige_awards = awards.find('a',{'aria-label':'See more awards and nominations'}).text\n",
        "    if prestige_awards!=\"Awards\":\n",
        "      awards_dict['awards_prestige_desc']  = prestige_awards\n",
        "      if \"Won\" in prestige_awards:\n",
        "        awards_prestige_wins = int(''.join(filter(str.isdigit, prestige_awards)))\n",
        "        \n",
        "      else:\n",
        "        awards_prestige_nominations = int(''.join(filter(str.isdigit, prestige_awards)))\n",
        "        \n",
        "    else:\n",
        "      awards_dict['awards_prestige']  = 0\n",
        "\n",
        "    # Find total awards\n",
        "    award_other = awards.find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text\n",
        "    award_other_counts = get_awards_info(award_other)\n",
        "    awards_dict['award_other_desc'] = award_other\n",
        "    awards_other_won = award_other_counts[0]\n",
        "    awards_other_nominations = award_other_counts[1]\n",
        "\n",
        "  awards_dict['awards_prestige_wins']  = awards_prestige_wins\n",
        "  awards_dict['awards_prestige_nominations']  = awards_prestige_nominations\n",
        "  awards_dict['awards_other_won'] = awards_other_won\n",
        "  awards_dict['awards_other_nominations'] = awards_other_nominations\n",
        "\n",
        "  return awards_dict\n",
        "\n",
        "artist_imdb_id = \"nm0798646\"\n",
        "artist_page = requests.get(f\"https://www.imdb.com/name/{artist_imdb_id}/\", headers=headers)\n",
        "artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "artist_dict = {}\n",
        "artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "artist_dict['artist_type'] = \"Director\"\n",
        "artist_dict['artist_url'] = artist_page\n",
        "collect_artist_awards(artist_page_soup)"
      ],
      "metadata": {
        "id": "4mbxHcfhHQhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Extract artist info"
      ],
      "metadata": {
        "id": "v3ImIU1h49Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist_info(artist_imdb_id,col_name):\n",
        "  artist_dict = {}\n",
        "\n",
        "  artist_url_page = f\"{base_url}/name/{artist_imdb_id}\"\n",
        "  artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "  artist_dict['artist_type'] = col_name.split('_')[0]\n",
        "  artist_dict['artist_url'] = artist_url_page\n",
        "\n",
        "  try:\n",
        "    artist_page = requests.get(artist_url_page, headers=headers)\n",
        "    artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "\n",
        "    artist_name = artist_page_soup.find('h1',{'data-testid':'hero__pageTitle'}).find('span').text.strip()\n",
        "    artist_dict['artist_name'] = artist_name\n",
        "\n",
        "    if artist_page_soup.find('span', string=\"Born\") is not None:\n",
        "      artist_birthday = artist_page_soup.find('span',string=\"Born\").findNextSibling().text\n",
        "      artist_dict['artist_birthday'] = artist_birthday\n",
        "      artist_dict['artist_age'] = extract_artist_age(artist_birthday)\n",
        "      if artist_dict['artist_age'] == None:\n",
        "        print(f\"Unable to extract age for {artist_name}. Value: {artist_birthday} Url: {artist_url_page}\")\n",
        "      \n",
        "    artist_bio = artist_page_soup.find('div',{'class':'ipc-html-content-inner-div'})\n",
        "    \n",
        "    if artist_bio!=None:\n",
        "      artist_dict['artist_bio'] = artist_bio.text\n",
        "      artist_gender = assume_gender(artist_bio.text)\n",
        "      \n",
        "    else:\n",
        "      artist_gender = \"Unknown\"\n",
        "\n",
        "    artist_dict['artist_gender'] = artist_gender\n",
        "\n",
        "    # Collect Rank\n",
        "    collect_artist_rank(artist_page_soup,artist_dict)\n",
        "    \n",
        "    # Collect Awards\n",
        "    awards_dict = collect_artist_awards(artist_page_soup)\n",
        "    artist_dict.update(awards_dict)\n",
        "\n",
        "    artist_title = artist_dict['artist_type']\n",
        "    if artist_title == \"Star\":\n",
        "      artist_title = \"Actress\" if artist_gender==\"Female\" else \"Actor\"\n",
        "\n",
        "    if artist_page_soup.find('h3',string=artist_title) is not None:\n",
        "      previous_work = artist_page_soup.find('h3',string=artist_title).find_next().find('li', string=\"Previous\")\n",
        "      if previous_work is not None:\n",
        "        previous_work = previous_work.find_next_sibling().text\n",
        "    elif artist_page_soup.find('li',string=\"Previous\") is not None:\n",
        "      previous_work = artist_page_soup.find('li',string=\"Previous\").find_next_sibling().text\n",
        "    else:\n",
        "      previous_work = 0\n",
        "      print(f\"Unable to get previous work for {artist_title}: {artist_name}. Url: {artist_url_page}\")\n",
        "      \n",
        "    artist_dict['previous_work'] = previous_work\n",
        "    artist_dict['__SuccsefullyCollectArtistDetails'] = True;\n",
        "\n",
        "    return artist_dict\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for artist: {artist_imdb_id}. Url: {artist_url_page}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    artist_dict['__SuccsefullyCollectArtistDetails'] = False;\n",
        "\n",
        "artist_imdb_id = \"nm13470591\"\n",
        "col_name = \"Director_3_imdb_id\"\n",
        "extract_artist_info(artist_imdb_id,col_name)"
      ],
      "metadata": {
        "id": "QVjKflwUhi1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Artist variables"
      ],
      "metadata": {
        "id": "YECMLiiB6Z42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artists_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/artists_dataset.csv\"\n",
        "if os.path.exists(artists_dataset_path):\n",
        "  artists_df = pd.read_csv(artists_dataset_path)\n",
        "  artists_list = artists_df.set_index('artist_imdb_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  artists_list = {}\n",
        "  artists_df = pd.DataFrame(artists_list)\n",
        "\n",
        "print(f\"artists_list contains {len(artists_list)} records\")\n",
        "artists_df.head(3)"
      ],
      "metadata": {
        "id": "1cQdE9jBpMHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Collect Artists"
      ],
      "metadata": {
        "id": "Q4R6_7X-5DvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_cols = [col for col in movie_dataset.columns if \"imdb_id\" in col]\n",
        "\n",
        "artists_skipped = 0\n",
        "artists_collected = 0\n",
        "artist_count = 1\n",
        "for i, row in movie_dataset.iterrows():\n",
        "  for col_name in artist_cols:\n",
        "    artist_dict = {'artist_collected':False}\n",
        "    artist_imdb_id = row[col_name]\n",
        "    if type(artist_imdb_id) != float:\n",
        "      if artist_imdb_id in artists_list.keys() and artists_list[artist_imdb_id]['artist_collected']==True:\n",
        "        artist_dict = artists_list[artist_imdb_id]\n",
        "        artist_dict['artist_collected']=True\n",
        "        artists_skipped += 1\n",
        "      else:\n",
        "        artist_output = extract_artist_info(artist_imdb_id,col_name)\n",
        "        if artist_output!=None:\n",
        "          artist_dict.update(artist_output)\n",
        "          artist_dict['artist_collected']=True\n",
        "        artists_collected += 1 \n",
        "        sleep(0.1)\n",
        "\n",
        "      artists_list[artist_imdb_id] = artist_dict\n",
        "      artist_count += 1\n",
        "      if artist_count%200 == 0:\n",
        "        artist_dataset = pd.DataFrame(artists_list).T\n",
        "        artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "        print(f\"\\nSaving progress. Run {artist_count} for movie {i}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")\n",
        "\n",
        "artist_dataset = pd.DataFrame(artists_list).T\n",
        "artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "print(f\"\\n\\nFinished process. Total: {artist_count}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")"
      ],
      "metadata": {
        "id": "3ILsPPc9dUkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_dataset.head(5)"
      ],
      "metadata": {
        "id": "-UoBsJHZ03SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build final dataset"
      ],
      "metadata": {
        "id": "_b0WUdg-jWDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go over the movie_dataset and convert the data to a manageable format"
      ],
      "metadata": {
        "id": "_6DUIv-EktM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/imdb_dataset.csv\"\n",
        "if os.path.exists(imdb_dataset_path):\n",
        "  imdb_df = pd.read_csv(imdb_dataset_path)\n",
        "  imdb_dict = imdb_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  imdb_dict = {}\n",
        "  imdb_df = pd.DataFrame(imdb_dict)\n",
        "\n",
        "print(f\"imdb_dict contains {len(imdb_dict)} records\")\n",
        "imdb_df.head(3)"
      ],
      "metadata": {
        "id": "YGESu4IYjViK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset.head(3).T"
      ],
      "metadata": {
        "id": "FVX2oaFQk9uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Convert string to number"
      ],
      "metadata": {
        "id": "rByBbY4inXha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_numbers(num_string):\n",
        "  try:\n",
        "    if not num_string:\n",
        "      return None\n",
        "    elif 'K' in num_string:\n",
        "        number = float(num_string.replace('K', '')) * 1000\n",
        "    elif 'M' in num_string:\n",
        "        number = float(num_string.replace('M', '')) * 1000000\n",
        "    else:\n",
        "        number = float(num_string.replace('$', '').replace(',', ''))\n",
        "    return number\n",
        "  except Exception as ex:\n",
        "    print(f\"Could not interpret value {num_string}\")\n",
        "\n",
        "\n",
        "\n",
        "print(convert_numbers('$14,300,000'))\n",
        "print(convert_numbers('3.3K'))\n",
        "print(convert_numbers('2.6M'))\n",
        "print(convert_numbers('2.6M'))\n",
        "print(convert_numbers('350000000.0'))\n",
        "print(convert_numbers('87'))\n",
        "print(convert_numbers('87.00'))\n",
        "print(convert_numbers(None))"
      ],
      "metadata": {
        "id": "K-TYX7b5lewn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "  if not text:\n",
        "    return 0\n",
        "  else:\n",
        "    words = text.split()\n",
        "    return len(words)\n",
        "\n",
        "print(count_words(\"Puss in Boots: The Last Wish\"))\n",
        "print(count_words(\"X\"))\n",
        "print(count_words(None))\n",
        "print(count_words(\"\"))"
      ],
      "metadata": {
        "id": "uoyoYKB4zHiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Rating to Rating Category"
      ],
      "metadata": {
        "id": "2CmSbq0aHQQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rating_to_category(movie_rating):\n",
        "    rating_category = {\n",
        "        \"NC-17\": \"R\",\n",
        "        \"16+\": \"R\",\n",
        "        \"18+\": \"R\",\n",
        "        \"Approved\": \"G\",\n",
        "        \"G\": \"G\",\n",
        "        \"M\": \"PG-13\",\n",
        "        \"Not Rated\": \"Unrated\",\n",
        "        \"PG\": \"PG-13\",\n",
        "        \"PG-13\": \"PG-13\",\n",
        "        \"R\": \"R\",\n",
        "        \"TV-14\": \"PG-13\",\n",
        "        \"TV-G\": \"G\",\n",
        "        \"TV-MA\": \"R\",\n",
        "        \"TV-PG\": \"PG-13\",\n",
        "        \"TV-Y\": \"G\",\n",
        "        \"TV-Y7\": \"G\",\n",
        "        \"Unrated\": \"Unrated\"\n",
        "    }\n",
        "    return rating_category.get(movie_rating, \"Unrated\")\n",
        "\n",
        "print(rating_to_category(\"M\"))\n",
        "print(rating_to_category(\"TV-Y\"))\n",
        "print(rating_to_category(\"\"))\n",
        "print(rating_to_category(None))\n",
        "print(rating_to_category(\"BadValue\"))"
      ],
      "metadata": {
        "id": "RZ6jHr_x3-zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Genere to Genere Category"
      ],
      "metadata": {
        "id": "DP_RMJj4HUe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def genre_list_to_catg(genre_list):\n",
        "  genre_dict = {\"genre__count\":0}\n",
        "  if type(genre_list) == str:\n",
        "    g_list = genre_list.strip().split(',')\n",
        "    genre_dict[\"genre__count\"] = len(g_list)\n",
        "  \n",
        "    for g in g_list:\n",
        "      genre_dict[f\"genere_{g.strip().lower()}\"] = True\n",
        "\n",
        "  return genre_dict\n",
        "\n",
        "print(genre_list_to_catg(\"Action, \"))\n",
        "print(genre_list_to_catg(\"Action, adventure, Fantasy\"))\n",
        "print(genre_list_to_catg(\"Biography, Comedy, Music\"))\n",
        "print(genre_list_to_catg(None))\n",
        "print(genre_list_to_catg(\"\"))"
      ],
      "metadata": {
        "id": "xuxlnV8P3t8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Language to Language Category"
      ],
      "metadata": {
        "id": "TLkpQsReHXdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def language_list_to_catg(language_list):\n",
        "  language_dict = {}\n",
        "  if type(language_list)==str:\n",
        "    l_list = language_list.strip().split(',')\n",
        "    language_dict[\"language__count\"] = len(l_list)\n",
        "\n",
        "    for l in l_list:\n",
        "        language_dict[f\"language_{l.strip().lower()}\"] = True\n",
        "  else:\n",
        "    language_dict[f\"language_english\"] = True\n",
        "    language_dict[\"language__count\"] = 1\n",
        "\n",
        "  return language_dict\n",
        "\n",
        "print(language_list_to_catg(\"English\"))\n",
        "print(language_list_to_catg(\"English,Mandarin,Cantonese\"))\n",
        "print(language_list_to_catg(None))\n",
        "print(language_list_to_catg(\"\"))"
      ],
      "metadata": {
        "id": "WFTvjyZl89Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Extract Crew Stats"
      ],
      "metadata": {
        "id": "FXIoXJkDHaxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artists_list['nm7414638']"
      ],
      "metadata": {
        "id": "njrlp1BVWb4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist_stats(row,movie_id):\n",
        "\n",
        "  artist_stats_dict = {}\n",
        "\n",
        "  movie_name = row['movie_name']\n",
        "\n",
        "  artist_cols = ['Star_1_imdb_id','Star_2_imdb_id','Star_3_imdb_id','Director_1_imdb_id','Director_2_imdb_id','Director_3_imdb_id','Writer_1_imdb_id','Writer_2_imdb_id','Writer_3_imdb_id']\n",
        "\n",
        "  #info to extract:\n",
        "  main_crew_count = 0\n",
        "  crew_age_sum = 0\n",
        "  crew_age_avg = 0\n",
        "  crew_age_missing = 0\n",
        "  crew_female_count = 0\n",
        "  crew_nonbinary_count = 0\n",
        "  crew_prestige_wins = 0\n",
        "  crew_prestige_nominations = 0\n",
        "  crew_awards_wins = 0\n",
        "  crew_awards_nominations = 0\n",
        "\n",
        "  for artist in artist_cols:\n",
        "    try:\n",
        "      artist_imdb_id = row.get(artist)\n",
        "      if type(artist_imdb_id) == str:\n",
        "        main_crew_count += 1\n",
        "\n",
        "        artist_data = artists_list.get(artist_imdb_id)\n",
        "        artist_name = artist_data.get('artist_name')\n",
        "        artist_gender = artist_data.get('artist_gender')\n",
        "        if artist_gender==\"Female\":\n",
        "          crew_female_count+=1\n",
        "        elif artist_gender==\"NonBinary\":\n",
        "          crew_nonbinary_count+=1\n",
        "\n",
        "        age = artist_data.get('artist_age')\n",
        "        #print(artist_data)\n",
        "        #print(artist_imdb_id,artist_name,age,artist_data['artist_age'])\n",
        "        if not age:\n",
        "          crew_age_missing += 1\n",
        "        else:\n",
        "          crew_age_sum += age\n",
        "\n",
        "        crew_prestige_wins += artist_data.get('awards_prestige_wins')\n",
        "        crew_prestige_nominations += artist_data.get('awards_prestige_nominations')\n",
        "        crew_awards_wins += artist_data.get('awards_other_won')\n",
        "        crew_awards_nominations += artist_data.get('awards_other_nominations')\n",
        "    except Exception as e:\n",
        "      print(f\"Failed extracting data for artist: {artist} - {artist_data.get('artist_name')}. \\nmovie_name: {movie_name}({movie_id}).\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "  if crew_age_sum: # Ag age is the sum age divided by the number of collected ages (total minus missing)\n",
        "    crew_age_avg = crew_age_sum/(main_crew_count-crew_age_missing)\n",
        "  else:\n",
        "    print(f'None of the crew for movie {movie_name}({movie_id} had their age listed in their bio page.')\n",
        "    crew_age_avg = None\n",
        "\n",
        "  artist_stats_dict['main_crew_count'] = main_crew_count\n",
        "  artist_stats_dict['crew_age_avg'] = crew_age_avg\n",
        "  artist_stats_dict['crew_age_missing'] = crew_age_missing\n",
        "  artist_stats_dict['crew_female_count'] = crew_female_count\n",
        "  artist_stats_dict['crew_nonbinary_count'] = crew_nonbinary_count\n",
        "  artist_stats_dict['crew_prestige_wins'] = crew_prestige_wins\n",
        "  artist_stats_dict['crew_prestige_nominations'] = crew_prestige_nominations\n",
        "  artist_stats_dict['crew_awards_wins'] = crew_awards_wins\n",
        "  artist_stats_dict['crew_awards_nominations'] = crew_awards_nominations\n",
        "  return artist_stats_dict\n",
        "\n",
        "extract_artist_stats(row,\"tt22061140\")"
      ],
      "metadata": {
        "id": "qD_ene6u_UPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_imdb_movie_dataset(movie_id,total_movie_dataset):\n",
        "\n",
        "  row = total_movie_dataset[movie_id]\n",
        "\n",
        "  amount_cols = ['budget_usd','runtime_min']\n",
        "\n",
        "  imdb_movie = {\"_finshed_successfully\":False}\n",
        "\n",
        "  for col in amount_cols:\n",
        "    imdb_movie[col] = convert_numbers(str(row[col]))\n",
        "\n",
        "  imdb_movie['title_length'] = count_words(row.get('movie_name'))\n",
        "  imdb_movie['movie_desc_length'] = count_words(row.get('movie_description'))\n",
        "  imdb_movie['rating_catg'] = rating_to_category(row.get('movie_rating'))\n",
        "  imdb_movie['movie_year'] = 2022 if row.get('movie_year') is None else row.get('movie_year')\n",
        "  imdb_movie['budget_currency'] = \"USD\" if row.get('budget_currency') is None else row.get('budget_currency')\n",
        "\n",
        "  # cast count:\n",
        "  for k in row.keys():\n",
        "    if 'cast_count' in k:\n",
        "      imdb_movie[k] = 0 if row[k] is None else row[k] \n",
        "\n",
        "  # genere:\n",
        "  movie_genre_dict = genre_list_to_catg(row.get('movie_genere'))\n",
        "  imdb_movie.update(movie_genre_dict)\n",
        "\n",
        "  # language:\n",
        "  languages_dict = language_list_to_catg(row.get('languages'))\n",
        "  imdb_movie.update(languages_dict)\n",
        "\n",
        "  # Get dependent columns:\n",
        "  imdb_movie['pred_metascore'] = row.get('movie_metascore')\n",
        "  imdb_movie['pred_user_review_count'] = convert_numbers(str(row.get('user_reviews_count')))\n",
        "  imdb_movie['pred_critic_review_count'] = convert_numbers(str(row.get('critic_reviews_count')))\n",
        "  imdb_movie['pred_total_vote_count'] = convert_numbers(str(row.get('movie_vote_num')))\n",
        "  imdb_movie['pred_gross_worldwide'] = convert_numbers(str(row.get('gross_worldwide')))\n",
        "  imdb_movie['pred_gross_us_canada'] = convert_numbers(str(row.get('gross_us_canada')))\n",
        "  imdb_movie['pred_opening_weekend_us_canada'] = convert_numbers(str(row.get('opening_weekend_us_canada')))\n",
        "\n",
        "  # Get crew stats:\n",
        "  crew_stats = extract_artist_stats(row,movie_id)\n",
        "  imdb_movie[\"_finshed_successfully\"] = True\n",
        "  imdb_movie.update(crew_stats)\n",
        "\n",
        "  #print(row)\n",
        "  return imdb_movie\n",
        "\n",
        "build_imdb_movie_dataset(\"tt21329580\",total_movie_dataset)"
      ],
      "metadata": {
        "id": "-XnCDaNOothJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/imdb_movie_dataset_raw.csv\"\n",
        "if os.path.exists(imdb_movie_dataset_path):\n",
        "  imdb_movie_df = pd.read_csv(imdb_movie_dataset_path)\n",
        "  imdb_movie_raw_list = imdb_movie_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  imdb_movie_raw_list = {}\n",
        "  imdb_movie_df = pd.DataFrame(imdb_movie_raw_list)\n",
        "\n",
        "print(f\"imdb_movie_raw_list contains {len(imdb_movie_raw_list)} records\")\n",
        "imdb_movie_df.head(3)"
      ],
      "metadata": {
        "id": "P_-nHFhwDAjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Finalize Dataset"
      ],
      "metadata": {
        "id": "enzukGWpnRXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_processed = 0\n",
        "movies_skipped = 0\n",
        "movie_count = 0\n",
        "for i, row in movie_dataset.iterrows():\n",
        "  movie_count += 1\n",
        "  try:\n",
        "    imdb_movie_record = {}\n",
        "    movie_id = row['movie_id']\n",
        "    if movie_id in imdb_movie_raw_list.keys() and imdb_movie_raw_list[movie_id]['_finshed_successfully']==True:\n",
        "      imdb_movie_record = imdb_movie_raw_list[movie_id]\n",
        "      movies_skipped += 1\n",
        "    else:\n",
        "      imdb_movie_record = build_imdb_movie_dataset(movie_id,total_movie_dataset)\n",
        "\n",
        "\n",
        "    imdb_movie_raw_list[movie_id] = imdb_movie_record\n",
        "  except Exception as e:\n",
        "    print(f\"Failed building finished data for movie: {movie_id}. \\nRaw Data: {row}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    imdb_movie_record['_finshed_successfully'] = False;\n",
        "\n",
        " \n",
        "imdb_movie_raw_dataset = pd.DataFrame(imdb_movie_raw_list).T\n",
        "print(f\"\\n\\nFinished process. Total: {movie_count}. movies_processed:{movies_processed}. movies_skipped:{movies_skipped}\")\n",
        "imdb_movie_raw_dataset.to_csv(imdb_movie_dataset_path, index=True, index_label=\"movie_id\")"
      ],
      "metadata": {
        "id": "v5sdDPzVj1ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "bWJBNAeMk_yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all nan values to 0s:\n",
        "\n",
        "for col in imdb_movie_raw_dataset.columns:\n",
        "    # Check if the column name starts with 'cast_count'\n",
        "    if col.startswith('cast_count_'):\n",
        "        # Replace NaN values with 0\n",
        "        imdb_movie_raw_dataset[col] = imdb_movie_raw_dataset[col].fillna(0)\n",
        "    elif col.startswith('language_') or col.startswith('genere_'):\n",
        "      # Replace NaN values with False\n",
        "        imdb_movie_raw_dataset[col] = imdb_movie_raw_dataset[col].fillna(False)\n",
        "\n",
        "\n",
        "\n",
        "imdb_movie_raw_dataset.to_csv(imdb_movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "k1UV4kU4Eu6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrSTAU-MMZH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "oXue_NbebNaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><b>Observing The Data</b><br>\n",
        "We will go over our different columns, make note of their scales and divide them into columns types for later preprocessing."
      ],
      "metadata": {
        "id": "al23cKd5kdJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_raw_dataset.head(3).T"
      ],
      "metadata": {
        "id": "8arIHcMjkgj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_raw_dataset.describe().round(3).T"
      ],
      "metadata": {
        "id": "T06GhDZeksBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon looking at our data we can split it into the following types:\n",
        "\n",
        "Textual Columns - We will not be able to use them as they appear currently and they will be dropped for now.\n",
        "Numerical Columns - We will need to scale these later on.\n",
        "Categorical Columns - We will need to convert these using One-Hot-Encoding.\n",
        "Binary Columns\n",
        "Result Column - This contain our Y values\n"
      ],
      "metadata": {
        "id": "ZeCzP1tBkzMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictor columns:\n",
        "y_metascore = ['pred_metascore']\n",
        "y_opening_weekend_us = ['pred_opening_weekend_us_canada']\n",
        "y_gross_us = ['pred_gross_us_canada']\n",
        "\n",
        "columns_to_drop = ['_finshed_successfully','artist','uri','movie_id','movie_year']\n",
        "\n",
        "categorical_columns = []\n",
        "binary_columns = []\n",
        "numerical_columns = []\n",
        "uncategorized_columns = []\n",
        "\n",
        "binary_threshold = 10 # Below 10 positive values this column will be dropped\n",
        "numerical_threshold = 10 # Below 10 total values this column will be dropped\n",
        "\n",
        "dtype_dict = imdb_movie_raw_dataset.dtypes\n",
        "for col, col_type in dtype_dict.items():\n",
        "  if col not in columns_to_drop:\n",
        "    # handle binary columns:\n",
        "    if col_type == bool:\n",
        "\n",
        "      true_count = imdb_movie_raw_dataset[col].sum()\n",
        "      \n",
        "      if true_count<binary_threshold:\n",
        "        print(f\"dropping column {col} since it has only {true_count} actual records\")\n",
        "        columns_to_drop.append(col)\n",
        "      else:\n",
        "        binary_columns.append(col)\n",
        "    \n",
        "    # handle numerical columns:\n",
        "    elif col_type in [float,int] :\n",
        "      \n",
        "      col_sum = imdb_movie_raw_dataset[col].sum()\n",
        "      if col_sum<numerical_threshold:\n",
        "        print(f\"dropping column {col} since it has only {col_sum} sum values records\")\n",
        "        columns_to_drop.append(col)\n",
        "      else:\n",
        "        numerical_columns.append(col)\n",
        "\n",
        "    elif col_type == object:\n",
        "      #Try to convert to float:\n",
        "      try:\n",
        "        imdb_movie_raw_dataset[col] = imdb_movie_raw_dataset[col].astype(float)\n",
        "        numerical_columns.append(col)\n",
        "        print(f\"col {col} was converted from type 'object' to type 'float'\")\n",
        "      # Check if categorical:\n",
        "      except:\n",
        "        if len(imdb_movie_raw_dataset[col].unique())<20:\n",
        "          print(f\"Col {col} is a categorical type column with {len(imdb_movie_raw_dataset[col].unique())} unique values:\\n      {imdb_movie_raw_dataset[col].unique()}\")\n",
        "          categorical_columns.append(col)\n",
        "        else:\n",
        "          print(f\"Unable to categorize column {col}\")\n",
        "          uncategorized_columns.append(col)\n",
        "    else:\n",
        "      print(col, col_type)\n",
        "      uncategorized_columns.append(col)\n",
        "\n",
        "print(f\"\\nOur Dataset has: \\n  {len(categorical_columns)} categorical_columns. \\n  {len(binary_columns)} binary_columns. \\n  {len(numerical_columns)} numerical_columns. \\n   {len(uncategorized_columns)} uncategorized_columns. \\n\")"
      ],
      "metadata": {
        "id": "UpglWTQIeA4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_raw_dataset[categorical_columns+uncategorized_columns+numerical_columns+uncategorized_columns].head(3)"
      ],
      "metadata": {
        "id": "zWQvTuV8kzvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle uncategorized columns:"
      ],
      "metadata": {
        "id": "qUZOcP3EtOkF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnGfLltFtU0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}