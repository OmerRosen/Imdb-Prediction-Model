{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_ZuJF2lhHRui4fu7P101KKc4AUqEmZvP",
      "authorship_tag": "ABX9TyOsnbs0beFJoHUwBoCpFLW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmerRosen/Kaggle/blob/main/IMDB_2022_Hit_or_Flop_Data_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB 2022 - Hit or Flop"
      ],
      "metadata": {
        "id": "NQFvvfWPy8yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mission Statement"
      ],
      "metadata": {
        "id": "y0Rjw492zB7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data To Collect"
      ],
      "metadata": {
        "id": "YgCYDZTUzHKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search box page:\n",
        "* Movie Id\n",
        "* Movie Title\n",
        "* Movie year\n",
        "* Rating\n",
        "* MetaScore - Outcome\n",
        "* Description\n",
        "* Poster\n",
        "* Directore name + Link\n",
        "* Stars\n",
        "* Votes - Output\n",
        "* Genre"
      ],
      "metadata": {
        "id": "B67t6dw23MyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Movie Page data\n",
        "* Movie Length\n",
        "* Rank\n",
        "* Writer\n",
        "* Star #1\n",
        "* Star #2\n",
        "* Star #3\n",
        "* User eviews\n",
        "* Critic reviews\n",
        "* Number of photos posted\n",
        "* Storyline - Text\n",
        "* Tag line\n",
        "* Release Date - Month\n",
        "* Country of origin\n",
        "* Additional Lanaguages\n",
        "* Country of filming\n",
        "* Production companies\n",
        "* Budget\n",
        "* Opening Weekend Date\n",
        "* Gross US & Canada - Output\n",
        "* Opening weekend US & Canada - Output\n",
        "* Gross worldwide - Output\n",
        "* Color - Color\n",
        "* Color - Black&White\n",
        "* Sound mix - Dolby Digital\n",
        "* Sound mix - Dolby Atmos\n",
        "* Aspect ratio"
      ],
      "metadata": {
        "id": "57uP49Tx3Za2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Director Page:\n",
        "* Director Age\n",
        "* Is Top 500?\n",
        "* Director Gender (Based on bio)\n",
        "* Previous film count - As Director\n",
        "* Previous film count - As Writer\n",
        "* Previous film count - As As Producer\n",
        "* Director Publicity listing count"
      ],
      "metadata": {
        "id": "GFrFPrn13upo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Information Abount Cast:\n",
        "* Full list of cast and their profile links\n",
        "* Number of cast members\n",
        "* Produced by - Is top 500?\n",
        "* Music by - Is top 500?\n",
        "* Cinematography by  - Is top 500\n",
        "* Film Editing by   - Is top 500\n",
        "* Art Direction by  - Is top 500\n",
        "* Number of Production Management\n",
        "* Number of Art Department\n",
        "* Number of Sound Department\n",
        "* Number of Camera and Electrical Department\n",
        "* Number of Editorial Department\n",
        "* Number of Music Department\n",
        "* Number of Additional Crew"
      ],
      "metadata": {
        "id": "WJsID_wt3ujg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Actor Page\n",
        "* Is Top 5000?\n",
        "* Is Top 500?\n",
        "* Is Top 100 (aka - Has numberical rank)\n",
        "* Is Top 10 (aka - Has numberical rank)\n",
        "* Numerical Rank (Could be none)\n",
        "* Gender\n",
        "* Age\n",
        "* Oscar nominations \n",
        "* Birth country"
      ],
      "metadata": {
        "id": "nI2XH-eX3ubL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggragated data:\n",
        "* How many male stars\n",
        "* How many female stars\n",
        "* Avrage cast memeber age\n",
        "* Max/Min age of cast member\n",
        "* Number of unique birth countries of actors\n",
        "* Total number of Oscar numinatior for cast\n",
        "* Num cast members in top 5000\n",
        "* Num cast memebers in top 500\n",
        "* Num cast members in top 100\n",
        "* Num cast members in top 10"
      ],
      "metadata": {
        "id": "iJMm4uv_zRNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB Scraper"
      ],
      "metadata": {
        "id": "miwov1QlN7-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "OCmEiQzqGt7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "import json\n",
        "from time import sleep\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import traceback\n"
      ],
      "metadata": {
        "id": "SoeHu2EVOyw6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set main variables"
      ],
      "metadata": {
        "id": "KOSm1vl34Dgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.imdb.com\"\n",
        "base_folder_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project\"\n",
        "\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "minimum_votes = 1000   # Minimum vote amount to collect movie\n",
        "start_point = 1       # Start from movie #1-50\n",
        "\n",
        "movie_search_url = f\"{base_url}/search/title/?title_type=feature&release_date={start_date},{end_date}&num_votes={minimum_votes},&languages=en&start={start_point}&user_rating=1.0,10.0&ref_=adv_nxt\"\n",
        "movie_search_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9aLLijszN2JX",
        "outputId": "bcd5521e-7f56-4ff7-cd36-faa74f82a93e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.imdb.com/search/title/?title_type=feature&release_date=2022-01-01,2022-12-31&num_votes=1000,&languages=en&start=1&user_rating=1.0,10.0&ref_=adv_nxt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
        "}\n",
        "\n",
        "list_of_50_movies = requests.get(f'{movie_search_url}', headers=headers, timeout=10)\n",
        "list_of_50_movies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPZnOmt7O4ZO",
        "outputId": "33bec913-c72d-4203-9846-4d295802e385"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_50_movies_soup = BeautifulSoup(list_of_50_movies.text, 'html.parser').find_all('div',{'class':'lister-item mode-advanced'})\n"
      ],
      "metadata": {
        "id": "fXP7YHhYPEFJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_search_page = list_of_50_movies_soup[0]"
      ],
      "metadata": {
        "id": "TPVLgEErQ1ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Movie Box details"
      ],
      "metadata": {
        "id": "tOOcl9NX4Pye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_basic_details(movie_search_page):\n",
        "  search_box_info = {}\n",
        "  search_box_info['movie_name'] = movie_search_page.find('a')\n",
        "  search_box_info['movie_page_url'] = f\"{base_url}{movie_search_page.find('a')['href']}\"\n",
        "\n",
        "  try:\n",
        "    search_box_info['movie_place'] = None if not movie_search_page.find('span',{'class':'lister-item-index unbold text-primary'}) else movie_search_page.find('span',{'class':'lister-item-index unbold text-primary'}).text.replace('.','')\n",
        "    search_box_info['movie_id'] = None if not search_box_info['movie_page_url'] else search_box_info['movie_page_url'].split('/')[-2]\n",
        "    search_box_info['movie_name'] = None if not movie_search_page.find('a').find('img') else movie_search_page.find('a').find('img')['alt'].strip()\n",
        "    search_box_info['movie_thubmnail'] = None if not movie_search_page.find('a').find('img') else movie_search_page.find('a').find('img')['src']\n",
        "    search_box_info['movie_metascore'] = None if not movie_search_page.find('span', {'class': 'metascore'}) else movie_search_page.find('span', {'class': 'metascore'}).text.strip()\n",
        "    search_box_info['movie_description'] = None if not movie_search_page.find_all('p',{'class':'text-muted'}) else movie_search_page.find_all('p',{'class':'text-muted'})[1].text.strip()\n",
        "    search_box_info['runtime_min'] = None if not movie_search_page.find('span',{'class':'runtime'}) else movie_search_page.find('span',{'class':'runtime'}).text.split(' ')[0]\n",
        "\n",
        "    bottom_box_info = movie_search_page.find('p',{'class':'sort-num_votes-visible'})\n",
        "    if bottom_box_info is not None:\n",
        "      search_box_info['movie_vote_num'] = bottom_box_info.find_all('span')[1]['data-value']\n",
        "\n",
        "    search_box_info['movie_rating'] = None if not movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'certificate'}) else movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'certificate'}).text.strip()\n",
        "    search_box_info['movie_genere'] = None if not movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'genre'}) else movie_search_page.find_all('p',{'class':'text-muted'})[0].find('span',{'class':'genre'}).text.strip()\n",
        "\n",
        "    search_box_info['__SuccsefullyCollectBasicDetails'] = True;\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for movie: {search_box_info['movie_name']}. \\nUrl: {search_box_info['movie_page_url']}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    search_box_info['__SuccsefullyCollectBasicDetails'] = False;\n",
        "\n",
        "\n",
        "  return search_box_info"
      ],
      "metadata": {
        "id": "ma8O2qtIaahp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_search_page = list_of_50_movies_soup[1]\n",
        "search_box_info = get_basic_details(movie_search_page)\n",
        "search_box_info\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSPtu7JccDLW",
        "outputId": "d410d1f9-9936-48ec-a641-ab54fddfa509"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie_name': 'Everything Everywhere All at Once',\n",
              " 'movie_page_url': 'https://www.imdb.com/title/tt6710474/?ref_=adv_li_i',\n",
              " 'movie_place': '2',\n",
              " 'movie_id': 'tt6710474',\n",
              " 'movie_thubmnail': 'https://m.media-amazon.com/images/S/sash/4FyxwxECzL-U1J8.png',\n",
              " 'movie_metascore': '81',\n",
              " 'movie_description': 'A middle-aged Chinese immigrant is swept up into an insane adventure in which she alone can save existence by exploring other universes and connecting with the lives she could have led.',\n",
              " 'runtime_min': '139',\n",
              " 'movie_vote_num': '434061',\n",
              " 'movie_rating': 'R',\n",
              " 'movie_genere': 'Action, Adventure, Comedy',\n",
              " '__SuccsefullyCollectBasicDetails': True}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_movie_url = \"https://www.imdb.com/title/tt14174168/?ref_=adv_li_i\"#search_box_info['movie_page_url']\n",
        "movie_main_page = requests.get(search_box_info['movie_page_url'], headers=headers)\n",
        "movie_main_page_soup = BeautifulSoup(movie_main_page.text, 'html.parser')"
      ],
      "metadata": {
        "id": "HcDJ2qcBlNUM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Year, Month and country"
      ],
      "metadata": {
        "id": "1NelYKPr8UUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_date_and_country(input_string):\n",
        "  if input_string!=None:\n",
        "    # Regular expression to match and extract the date and country\n",
        "    pattern = r'(\\w+)\\s(\\d+),\\s(\\d+)\\s\\((.*?)\\)'\n",
        "    match = re.search(pattern, input_string)\n",
        "    \n",
        "    if match:\n",
        "        month, day, year, country = match.groups()\n",
        "        return year, month, country\n",
        "    else:\n",
        "        return None,None,None\n",
        "  else:\n",
        "        return None,None,None\n",
        "\n",
        "# Test the function\n",
        "strings = [\n",
        "    \"October 28, 2022 (Netherlands)\",\n",
        "    \"March 18, 2022 (Netherlands)\",\n",
        "    \"November 11, 2022 (United States)\",\n",
        "    \"December 12, 2022 (Netherlands)\",\n",
        "    \"April 24, 2023 (Netherlands)\",\n",
        "    \"November 29, 2022 (Netherlands)\",\n",
        "    \"January 16, 2023 (Netherlands)\",\n",
        "    \"March 18, 2022 (Finland)\",\n",
        "    \"January 10, 2023 (United States)\",\n",
        "    \"November 18, 2022 (United States)\",\n",
        "    \"March 3, 2023 (United States)\",\n",
        "    \"March 2, 2023 (United States)\",\n",
        "    \"January 25, 2023 (Netherlands)\",\n",
        "    \"January 27, 2023 (Netherlands)\",\n",
        "    \"July 22, 2022 (United Kingdom)\",\n",
        "    \"November 22, 2022 (United States)\",\n",
        "    'September 7, 2022 (United States)'\n",
        "]\n",
        "\n",
        "for s in strings:\n",
        "    print(extract_date_and_country(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmdnmCNE8ZKZ",
        "outputId": "899e5f23-f53b-4c08-b5ed-33ef64b205a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2022', 'October', 'Netherlands')\n",
            "('2022', 'March', 'Netherlands')\n",
            "('2022', 'November', 'United States')\n",
            "('2022', 'December', 'Netherlands')\n",
            "('2023', 'April', 'Netherlands')\n",
            "('2022', 'November', 'Netherlands')\n",
            "('2023', 'January', 'Netherlands')\n",
            "('2022', 'March', 'Finland')\n",
            "('2023', 'January', 'United States')\n",
            "('2022', 'November', 'United States')\n",
            "('2023', 'March', 'United States')\n",
            "('2023', 'March', 'United States')\n",
            "('2023', 'January', 'Netherlands')\n",
            "('2023', 'January', 'Netherlands')\n",
            "('2022', 'July', 'United Kingdom')\n",
            "('2022', 'November', 'United States')\n",
            "('2022', 'September', 'United States')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Extract Movie Artists"
      ],
      "metadata": {
        "id": "Ui9hyYvhG_R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist(artist_type, movie_main_page_soup):\n",
        "\n",
        "  item_dict = {}\n",
        "\n",
        "  search_result = movie_main_page_soup.find(string=f\"{artist_type}s\") \n",
        "  if search_result==None:\n",
        "    search_result = movie_main_page_soup.find(string=artist_type) \n",
        "  \n",
        "  search_item_list = []\n",
        "  try:\n",
        "    if search_result!=None:\n",
        "      search_item_list = search_result.find_parent().find_next_sibling().find_all('a')\n",
        "    \n",
        "    item_dict[f\"{artist_type}_count\"] = len(search_item_list)\n",
        "\n",
        "    for i,item in enumerate(search_item_list):\n",
        "      artisc_name = item.text.strip()\n",
        "      artisc_url = item['href']\n",
        "      artist_id = artisc_url.split('/')[2]\n",
        "      item_dict[f\"{artist_type}_{i+1}_name\"] = artisc_name\n",
        "      #item_dict[f\"{artist_type}_{i+1}_url\"] = artisc_url\n",
        "      item_dict[f\"{artist_type}_{i+1}_imdb_id\"] = artist_id\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Failed extracting data for artist_type: {artist_type}. \\.\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "  return item_dict\n",
        "\n",
        "print(extract_artist(\"Director\", movie_main_page_soup))\n",
        "print(extract_artist(\"Writer\", movie_main_page_soup))\n",
        "print(extract_artist(\"Star\", movie_main_page_soup))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLMezvBZ8q3N",
        "outputId": "197fc6e6-277b-482e-9ef6-2e4c1d53e25d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Director_count': 2, 'Director_1_name': 'Daniel Kwan', 'Director_1_imdb_id': 'nm3453283', 'Director_2_name': 'Daniel Scheinert', 'Director_2_imdb_id': 'nm3215397'}\n",
            "{'Writer_count': 2, 'Writer_1_name': 'Daniel Kwan', 'Writer_1_imdb_id': 'nm3453283', 'Writer_2_name': 'Daniel Scheinert', 'Writer_2_imdb_id': 'nm3215397'}\n",
            "{'Star_count': 3, 'Star_1_name': 'Michelle Yeoh', 'Star_1_imdb_id': 'nm0000706', 'Star_2_name': 'Stephanie Hsu', 'Star_2_imdb_id': 'nm3513533', 'Star_3_name': 'Jamie Lee Curtis', 'Star_3_imdb_id': 'nm0000130'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Perform Currency Conversion"
      ],
      "metadata": {
        "id": "t8ANYROE8boz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "currency_codes = {\n",
        "    \"$\":\"USD\",\n",
        "    \"€\":\"EUR\",\n",
        "    \"£\":\"GBP\",\n",
        "    \"₹\":\"INR\",\n",
        "    \"â‚¬\": \"EUR\",\n",
        "    \"â‚¹\": \"INR\",\n",
        "    \"CA$\": \"CAD\",\n",
        "    \"NOKÂ\": \"NOK\",\n",
        "    \"Â£\": \"GBP\",\n",
        "    \"CHF\": \"CHF\",\n",
        "    \"Â¥\": \"JPY\",\n",
        "    \"PKR\": \"PKR\",\n",
        "    \"A$\": \"AUD\",\n",
        "    \"CZK\": \"CZK\",\n",
        "    \"RUR\": \"RUB\",\n",
        "    \"NZ$\": \"NZD\",\n",
        "    \"MYR\": \"MYR\",\n",
        "    \"NGN\": \"NGN\",\n",
        "    \"NOK\":\"NOK\",\n",
        "    \"A$\":\"AUD\",\n",
        "    \"â‚¬\":\"EUR\",\n",
        "    \"â‚¹\":\"INR\",\n",
        "    \"Â£\":\"GBP\",\n",
        "    \"CA$\":\"CAD\",\n",
        "    \"CHFÂ \":\"CHF\",\n",
        "    \"MYRÂ \":\"MYR\",\n",
        "    \"NGNÂ \":\"NGN\",\n",
        "    \"NOKÂ \":\"NOK\",\n",
        "    \"NZ$\":\"NZD\",\n",
        "    \"PKRÂ \":\"PKR\",\n",
        "    \"RURÂ \":\"RUB\",\n",
        "    \"IRR \":\"IRR\"\n",
        "}\n",
        "\n",
        "\n",
        "currency_conversion_values = {}\n"
      ],
      "metadata": {
        "id": "xTQyDlNNRMTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_currency_symbol(s):\n",
        "    match = re.search(r\"[^\\d]+\", s)\n",
        "    if match:\n",
        "        return match.group(0).strip()\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "Ffkj0oe7Vmee"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_currency_code(amount_string):\n",
        "  currency_symbol = extract_currency_symbol(amount_string)\n",
        "  if currency_symbol in currency_codes:\n",
        "      return currency_codes[currency_symbol]\n",
        "  else:\n",
        "    print(f\"Could not find a value for: {currency_symbol} in {amount_string}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "LFYkrlxHWeMw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_numerical_value(string):\n",
        "    # Remove all non-numeric characters from the string\n",
        "    numerical_string = re.sub(r\"[^\\d.]+\", \"\", string)\n",
        "    # Convert the string to a float and return it\n",
        "    return float(numerical_string)"
      ],
      "metadata": {
        "id": "q_2ySIZiXwK8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(f'{base_folder_path}/openexchangerates.txt', 'r') as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "api_key\n",
        "\n",
        "def convert_string_amount_to_usd(amount):\n",
        "\n",
        "  # get the currency code and amount value\n",
        "  currency_code = get_currency_code(amount)\n",
        "  original_amount = extract_numerical_value(amount)\n",
        "  usd_amount = None\n",
        "\n",
        "  if currency_code==None:\n",
        "    usd_amount=None\n",
        "  elif currency_code!=\"USD\":\n",
        "  \n",
        "    if currency_code in currency_conversion_values:\n",
        "      exchange_rate = currency_conversion_values[currency_code]\n",
        "    else:\n",
        "      # make API request to get exchange rate for the currency code\n",
        "      url = f\"https://openexchangerates.org/api/latest.json?app_id={api_key}&symbols={currency_code}\"\n",
        "      print(amount,currency_code,original_amount,url)\n",
        "      response = requests.get(url)\n",
        "      print(response)\n",
        "      # parse the exchange rate from the API response\n",
        "      exchange_rate = response.json()[\"rates\"][currency_code]\n",
        "      \n",
        "      currency_conversion_values[currency_code] = exchange_rate\n",
        "      \n",
        "      # calculate the USD equivalent amount\n",
        "      usd_amount = round(original_amount / exchange_rate)\n",
        "      \n",
        "      print(f\"{amount} {currency_code} = {usd_amount} USD\")\n",
        "  else:\n",
        "    usd_amount = original_amount\n",
        "\n",
        "  return usd_amount,original_amount,currency_code\n",
        "\n",
        "\n",
        "\n",
        "convert_string_amount_to_usd(\"CA$15,000\")\n",
        "convert_string_amount_to_usd(\"NOKÂ 80,200,000\")\n",
        "convert_string_amount_to_usd(\"NOKÂ 20,000,000\")\n",
        "convert_string_amount_to_usd(\"â‚¹3,500,000,000\")\n",
        "currency_conversion_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY3pGk9-N4t9",
        "outputId": "a30ec9bb-5da9-404d-dd37-9404ca125bd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CA$15,000 CAD 15000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=CAD\n",
            "<Response [200]>\n",
            "CA$15,000 CAD = 11008 USD\n",
            "NOKÂ 80,200,000 NOK 80200000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=NOK\n",
            "<Response [200]>\n",
            "NOKÂ 80,200,000 NOK = 7463174 USD\n",
            "â‚¹3,500,000,000 INR 3500000000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=INR\n",
            "<Response [200]>\n",
            "â‚¹3,500,000,000 INR = 42786502 USD\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CAD': 1.362617, 'NOK': 10.746098, 'INR': 81.801499}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get Movie Cast List and count"
      ],
      "metadata": {
        "id": "tNiDUkqFAa-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cast_list(cast_page_url):\n",
        "\n",
        "  cast_counts = {'cast_count_total':0}\n",
        "\n",
        "  cast_page = requests.get(cast_page_url, headers=headers)\n",
        "  cast_page_soup = BeautifulSoup(cast_page.text, 'html.parser')   \n",
        "\n",
        "  cast_groups = cast_page_soup.find_all('h4')\n",
        "\n",
        "  for cast_group in cast_groups:\n",
        "    try:\n",
        "      group_name = cast_group['id']\n",
        "      #print(group_name)\n",
        "      group_list = cast_group.find_next_sibling()\n",
        "      group_count = 0\n",
        "      if group_list is not None:\n",
        "        group_list = group_list.findAll('tr')\n",
        "        group_count = len(group_list)\n",
        "      cast_counts[f\"cast_count_{group_name}\"] = group_count\n",
        "      cast_counts['cast_count_total'] += group_count\n",
        "    except Exception as ex:\n",
        "      pass\n",
        "  return cast_counts\n",
        "\n",
        "get_cast_list(\"https://www.imdb.com/title/tt14174168/fullcredits\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_2zu-lf7BAy",
        "outputId": "b3e414e0-b9c4-4ae0-8389-255ae36f6967"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cast_count_total': 156,\n",
              " 'cast_count_director': 1,\n",
              " 'cast_count_writer': 2,\n",
              " 'cast_count_cast': 26,\n",
              " 'cast_count_producer': 28,\n",
              " 'cast_count_composer': 1,\n",
              " 'cast_count_cinematographer': 1,\n",
              " 'cast_count_editor': 1,\n",
              " 'cast_count_casting_director': 1,\n",
              " 'cast_count_production_designer': 2,\n",
              " 'cast_count_art_director': 1,\n",
              " 'cast_count_costume_designer': 1,\n",
              " 'cast_count_make_up_department': 4,\n",
              " 'cast_count_production_manager': 1,\n",
              " 'cast_count_assistant_director': 4,\n",
              " 'cast_count_art_department': 6,\n",
              " 'cast_count_sound_department': 7,\n",
              " 'cast_count_visual_effects': 12,\n",
              " 'cast_count_stunts': 2,\n",
              " 'cast_count_camera_department': 16,\n",
              " 'cast_count_costume_department': 2,\n",
              " 'cast_count_editorial_department': 5,\n",
              " 'cast_count_music_department': 1,\n",
              " 'cast_count_script_department': 1,\n",
              " 'cast_count_transportation_department': 1,\n",
              " 'cast_count_miscellaneous': 19,\n",
              " 'cast_count_thanks': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Function: Get Movie Page Extanded Details"
      ],
      "metadata": {
        "id": "tQaXU0Ib4V6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_extended_datails(movie_page_url, movie_name):\n",
        "  movie_page_dict = {}\n",
        "\n",
        "  try:\n",
        "\n",
        "    movie_main_page = requests.get(movie_page_url, headers=headers)\n",
        "    movie_main_page_soup = BeautifulSoup(movie_main_page.text, 'html.parser')   \n",
        "\n",
        "    year_rating = movie_main_page_soup.find('ul',{\"class\":\"ipc-inline-list ipc-inline-list--show-dividers sc-afe43def-4 kdXikI baseAlt\"}).find_all('a')\n",
        "\n",
        "    movie_page_dict['movie_year'] = year_rating[0].text if len(year_rating)>0 else None\n",
        "    movie_page_dict['movie_rating'] = year_rating[1].text if len(year_rating)>1 else None\n",
        "\n",
        "    director_dict = extract_artist(\"Director\", movie_main_page_soup)\n",
        "    if director_dict[f\"Director_count\"] == 0:\n",
        "      print(f\"No Director found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(director_dict)\n",
        "\n",
        "    writer_dict = extract_artist(\"Writer\", movie_main_page_soup)\n",
        "    if writer_dict[f\"Writer_count\"] == 0:\n",
        "      print(f\"No Writer found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(writer_dict)\n",
        "\n",
        "    star_dict = extract_artist(\"Star\", movie_main_page_soup)\n",
        "    if star_dict[f\"Star_count\"] == 0:\n",
        "      print(f\"No Star found for movie {movie_name}. Url: {movie_page_url}\")\n",
        "    movie_page_dict.update(star_dict)\n",
        "\n",
        "    user_rating = movie_main_page_soup.find('span',{'class':'sc-bde20123-1 iZlgcd'})\n",
        "    if user_rating is not None:\n",
        "      user_rating = user_rating.text\n",
        "    movie_page_dict['user_rating'] = user_rating\n",
        "\n",
        "    review_scores = movie_main_page_soup.find_all('span',{'class':'score'})\n",
        "    movie_page_dict['user_reviews_count'] = review_scores[0].text if len(review_scores)>0 else None\n",
        "    movie_page_dict['critic_reviews_count'] = review_scores[1].text if len(review_scores)>1 else None\n",
        "\n",
        "    #movie_page_dict['release_date'] = movie_main_page_soup.find('a',{'class':'ipc-metadata-list-item__label ipc-metadata-list-item__label--link'}, string=\"Release date\").find_parent().find('a',{'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'}).text.split('(')[0].strip()\n",
        "    #movie_page_dict['release_date']\n",
        "    \n",
        "\n",
        "    movie_page_dict['budget'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Budget\")\n",
        "    if (movie_page_dict['budget']!=None):\n",
        "      movie_page_dict['budget'] = movie_page_dict['budget'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "\n",
        "      usd_amount,original_amount,currency_code = convert_string_amount_to_usd(movie_page_dict['budget'])\n",
        "      movie_page_dict['budget_usd'] = usd_amount\n",
        "      movie_page_dict['budget_currency'] = currency_code\n",
        "\n",
        "    movie_page_dict['gross_worldwide'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Gross worldwide\")\n",
        "    if (movie_page_dict['gross_worldwide']!=None):\n",
        "      movie_page_dict['gross_worldwide'] = movie_page_dict['gross_worldwide'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['gross_worldwide'], _, _ = convert_string_amount_to_usd(movie_page_dict['gross_worldwide'])\n",
        "\n",
        "    movie_page_dict['gross_us_canada'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Gross US & Canada\")\n",
        "    if (movie_page_dict['gross_us_canada']!=None):\n",
        "      movie_page_dict['gross_us_canada'] = movie_page_dict['gross_us_canada'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['gross_us_canada'], _, _ = convert_string_amount_to_usd(movie_page_dict['gross_us_canada'])\n",
        "\n",
        "    movie_page_dict['opening_weekend_us_canada'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Opening weekend US & Canada\")\n",
        "    if (movie_page_dict['opening_weekend_us_canada']!=None):\n",
        "      movie_page_dict['opening_weekend_us_canada'] = movie_page_dict['opening_weekend_us_canada'].find_next_sibling().find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text.split('(')[0].strip()\n",
        "      movie_page_dict['opening_weekend_us_canada'], _, _ = convert_string_amount_to_usd(movie_page_dict['opening_weekend_us_canada'])\n",
        "\n",
        "    movie_page_dict['origin_country'] = movie_main_page_soup.find('span',{'class':'ipc-metadata-list-item__label'}, string=\"Country of origin\")\n",
        "    if (movie_page_dict['origin_country']!=None):\n",
        "      movie_page_dict['origin_country'] = movie_page_dict['origin_country'].find_next_sibling().find('a').text.split('(')[0].strip()\n",
        "\n",
        "    movie_page_dict['release_date'] = movie_main_page_soup.find('a',{'class':'ipc-metadata-list-item__label'}, string=\"Release date\")\n",
        "    if (movie_page_dict['release_date']!=None):\n",
        "      movie_page_dict['release_date'] = movie_page_dict['release_date'].find_next_sibling().find('a').text\n",
        "\n",
        "    year, month, country = extract_date_and_country(movie_page_dict['release_date']);\n",
        "    movie_page_dict['release_year'] = year\n",
        "    movie_page_dict['release_month'] = month\n",
        "    movie_page_dict['release_country'] = country\n",
        "\n",
        "    languages = movie_main_page_soup.find('span',string=\"Language\") if movie_main_page_soup.find('span',string=\"Languages\") is None else movie_main_page_soup.find('span',string=\"Languages\")\n",
        "    languages = [] if not languages else languages.find_next_sibling().find_all('a')\n",
        "    movie_page_dict['languages'] = \",\".join([language.text for language in languages])\n",
        "\n",
        "    movie_page_dict['__SuccsefullyCollectExtandedDetails'] = True;\n",
        "\n",
        "    ## Collect cast count for movie:\n",
        "    movie_id = movie_page_url.split('/')[-2]\n",
        "    cast_page_url = f\"https://www.imdb.com/title/{movie_id}/fullcredits\"\n",
        "    cast_list = get_cast_list(cast_page_url)\n",
        "    movie_page_dict.update(cast_list)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for movie: {movie_name}. \\nUrl: {movie_page_url}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    movie_page_dict['__SuccsefullyCollectExtandedDetails'] = False;\n",
        "\n",
        "  return movie_page_dict\n",
        "\n",
        "\n",
        "get_extended_datails(\"https://www.imdb.com/title/tt13070038/?ref_=adv_li_i\",\"After Ever Happy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH4irJSLculw",
        "outputId": "8d919055-2bf5-4133-e5bf-588c7cdb68e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie_year': '2022',\n",
              " 'movie_rating': 'R',\n",
              " 'Director_count': 1,\n",
              " 'Director_1_name': 'Castille Landon',\n",
              " 'Director_1_imdb_id': 'nm2500541',\n",
              " 'Writer_count': 2,\n",
              " 'Writer_1_name': 'Anna Todd',\n",
              " 'Writer_1_imdb_id': 'nm6849771',\n",
              " 'Writer_2_name': 'Sharon Soboil',\n",
              " 'Writer_2_imdb_id': 'nm0757267',\n",
              " 'Star_count': 3,\n",
              " 'Star_1_name': 'Josephine Langford',\n",
              " 'Star_1_imdb_id': 'nm6466214',\n",
              " 'Star_2_name': 'Hero Fiennes Tiffin',\n",
              " 'Star_2_imdb_id': 'nm2842005',\n",
              " 'Star_3_name': 'Louise Lombard',\n",
              " 'Star_3_imdb_id': 'nm0518321',\n",
              " 'user_rating': '4.5',\n",
              " 'user_reviews_count': '63',\n",
              " 'critic_reviews_count': '36',\n",
              " 'budget': None,\n",
              " 'gross_worldwide': 19155062.0,\n",
              " 'gross_us_canada': 1072750.0,\n",
              " 'opening_weekend_us_canada': 114993.0,\n",
              " 'origin_country': 'United States',\n",
              " 'release_date': 'September 7, 2022 (United States)',\n",
              " 'release_year': '2022',\n",
              " 'release_month': 'September',\n",
              " 'release_country': 'United States',\n",
              " 'languages': 'English',\n",
              " '__SuccsefullyCollectExtandedDetails': True,\n",
              " 'cast_count_total': 160,\n",
              " 'cast_count_director': 1,\n",
              " 'cast_count_writer': 3,\n",
              " 'cast_count_cast': 25,\n",
              " 'cast_count_producer': 14,\n",
              " 'cast_count_composer': 1,\n",
              " 'cast_count_cinematographer': 2,\n",
              " 'cast_count_editor': 1,\n",
              " 'cast_count_casting_director': 3,\n",
              " 'cast_count_production_designer': 1,\n",
              " 'cast_count_art_director': 1,\n",
              " 'cast_count_set_decorator': 1,\n",
              " 'cast_count_costume_designer': 1,\n",
              " 'cast_count_make_up_department': 7,\n",
              " 'cast_count_production_manager': 5,\n",
              " 'cast_count_assistant_director': 9,\n",
              " 'cast_count_art_department': 6,\n",
              " 'cast_count_sound_department': 9,\n",
              " 'cast_count_visual_effects': 4,\n",
              " 'cast_count_stunts': 1,\n",
              " 'cast_count_camera_department': 9,\n",
              " 'cast_count_casting_department': 3,\n",
              " 'cast_count_costume_department': 4,\n",
              " 'cast_count_editorial_department': 2,\n",
              " 'cast_count_location_management': 4,\n",
              " 'cast_count_music_department': 9,\n",
              " 'cast_count_script_department': 1,\n",
              " 'cast_count_miscellaneous': 32,\n",
              " 'cast_count_thanks': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(search_box_info['movie_page_url'],search_box_info['movie_name'])\n",
        "# cast_url = movie_main_page_soup.find('a',{'class':'ipc-metadata-list-item__label ipc-metadata-list-item__label--link'})['href']\n",
        "# cast_url = f\"{base_url}{cast_url}\"\n",
        "# cast_url"
      ],
      "metadata": {
        "id": "vEii_FS-9zTJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters:\n",
        "base_url = \"https://www.imdb.com\"\n",
        "\n",
        "start_date = \"2018-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "minimum_votes = 1000 # Minimum vote amount to coolect movie\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"}"
      ],
      "metadata": {
        "id": "NZCEUr1_HFkQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Get next movie batch"
      ],
      "metadata": {
        "id": "9g5RPMkeVjie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic parameters:\n",
        "\n",
        "def get_50_movie_batch(start_point, minimum_votes = 250, start_date = \"2022-01-01\", end_date = \"2022-12-31\", print_results = False):\n",
        "  movie_search_url_50_batch = f\"{base_url}/search/title/?title_type=feature&release_date={start_date},{end_date}&num_votes={minimum_votes},&user_rating=1.0,10.0&countries=us&languages=en&start={start_point}&user_rating=1.0,10.0&ref_=adv_nxt\"\n",
        "  \n",
        "  search_page = requests.get(f'{movie_search_url_50_batch}', headers=headers, timeout=10)\n",
        "  search_page_soup = BeautifulSoup(search_page.text, 'html.parser')\n",
        "  list_of_50_movies_soup = search_page_soup.find_all('div',{'class':'lister-item mode-advanced'})\n",
        "\n",
        "  max_num_of_results = search_page_soup.find('div',{'class':'desc'}).find('span').text.split(' ')[2].replace(\",\", \"\")\n",
        "  max_num_of_results = int(max_num_of_results)\n",
        "  if print_results: print(f\"Start point: {start_point}. start_date: {start_date}. end_date: {end_date}. \\nTotal Movies: {max_num_of_results} \\nsearch url: {movie_search_url_50_batch}\")\n",
        "\n",
        "  #print(f\"max_num_of_results: {max_num_of_results}\")\n",
        "  return(list_of_50_movies_soup,max_num_of_results)\n",
        "\n",
        "list_of_50_movies_soup,max_num_of_results = get_50_movie_batch(start_point = 1, minimum_votes = minimum_votes, start_date = start_date, end_date = end_date, print_results = True)"
      ],
      "metadata": {
        "id": "RYjnulARhT5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e7c3fa-7b96-4c90-8ca1-187fce8a1779"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start point: 1. start_date: 2018-01-01. end_date: 2022-12-31. \n",
            "Total Movies: 2407 \n",
            "search url: https://www.imdb.com/search/title/?title_type=feature&release_date=2018-01-01,2022-12-31&num_votes=1000,&user_rating=1.0,10.0&countries=us&languages=en&start=1&user_rating=1.0,10.0&ref_=adv_nxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/total_movie_dataset.csv\"\n",
        "if os.path.exists(movie_dataset_path):\n",
        "  movie_df = pd.read_csv(movie_dataset_path)\n",
        "  total_movie_dataset = movie_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  total_movie_dataset = {}\n",
        "  movie_df = pd.DataFrame(total_movie_dataset)\n",
        "\n",
        "print(f\"total_movie_dataset contains {len(total_movie_dataset)} records\")\n",
        "movie_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "1HHWreXyWqRe",
        "outputId": "a415f8b3-e373-468f-e087-f12ddc2b7d2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_movie_dataset contains 0 records\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e814d7f-4fa0-453b-bf0d-3decc210ca03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e814d7f-4fa0-453b-bf0d-3decc210ca03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e814d7f-4fa0-453b-bf0d-3decc210ca03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e814d7f-4fa0-453b-bf0d-3decc210ca03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Collecting movies from IMDB"
      ],
      "metadata": {
        "id": "TxMZRWuGG3SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_point = 1 # Start from movie #1-50\n",
        "\n",
        "basic_data_collected = 0\n",
        "basic_data_skipped = 0\n",
        "extended_data_collected = 0\n",
        "extended_data_skipped = 0\n",
        "\n",
        "count = 1\n",
        "while start_point < max_num_of_results-50:\n",
        "\n",
        "  list_of_50_movies_soup,num_of_results = get_50_movie_batch(start_point = start_point, minimum_votes = minimum_votes, start_date = start_date, end_date = end_date)\n",
        "  if count==1: print(f\"Starting run collecting movies. Total of {num_of_results} movies to be collected.\")\n",
        "\n",
        "  for i,movie in enumerate(list_of_50_movies_soup):\n",
        "    movie_data = {'__SuccsefullyCollectBasicDetails':False, '__SuccsefullyCollectExtandedDetails':False}\n",
        "\n",
        "    basic_data = get_basic_details(movie)\n",
        "    movie_id = basic_data['movie_id']\n",
        "\n",
        "    try:\n",
        "      if movie_id in total_movie_dataset.keys():\n",
        "        movie_data = total_movie_dataset[movie_id]\n",
        "\n",
        "      if movie_data['__SuccsefullyCollectBasicDetails']==True:\n",
        "        basic_data_skipped += 1\n",
        "      else:\n",
        "        basic_data_collected += 1\n",
        "        movie_data.update(basic_data)\n",
        "\n",
        "      if movie_data['__SuccsefullyCollectExtandedDetails']==True:\n",
        "        extended_data_skipped += 1\n",
        "      else:\n",
        "        extended_data_collected += 1\n",
        "        extended_data = get_extended_datails(basic_data['movie_page_url'],basic_data['movie_name'])\n",
        "        movie_data.update(extended_data)\n",
        "\n",
        "        sleep(0.1)\n",
        "    except Exception as e:\n",
        "      print(f\"Failed running cursor for movie: {movie_id}. \\nUrl: {basic_data['movie_page_url']}.\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "    total_movie_dataset[movie_id] = movie_data\n",
        "    count+= 1\n",
        "\n",
        "    if (count%200 == 0):\n",
        "      print(f\"\\nRun number: {count}. basic_data_collected: {basic_data_collected}. extended_data_collected: {extended_data_collected}. basic_data_skipped: {basic_data_skipped}. extended_data_skipped: {extended_data_skipped}\")\n",
        "\n",
        "\n",
        "  movie_dataset = pd.DataFrame(total_movie_dataset).T\n",
        "  movie_dataset.to_csv(movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "\n",
        "  start_point += 50\n",
        "\n",
        "print(f\"\\nRun number: {count}. \\nbasic_data_collected: {basic_data_collected}. \\nextended_data_collected: {extended_data_collected}. \\nbasic_data_skipped: {basic_data_skipped}. \\nextended_data_skipped: {extended_data_skipped}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASPUpIMHT2J",
        "outputId": "f360d616-09c0-41dd-e846-0c6a4658f1e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting run collecting movies. Total of 2407 movies to be collected.\n",
            "€10,000,000 EUR 10000000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=EUR\n",
            "<Response [200]>\n",
            "€10,000,000 EUR = 11001027 USD\n",
            "\n",
            "Run number: 200. basic_data_collected: 199. extended_data_collected: 199. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 400. basic_data_collected: 399. extended_data_collected: 399. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 600. basic_data_collected: 599. extended_data_collected: 599. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 800. basic_data_collected: 799. extended_data_collected: 799. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 1000. basic_data_collected: 999. extended_data_collected: 999. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "Failed extracting data for movie: The Resort. \n",
            "Url: https://www.imdb.com/title/tt12163074/?ref_=adv_li_i.\n",
            " Error:\n",
            "('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
            "    conn.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 419, in connect\n",
            "    self.sock = ssl_wrap_socket(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
            "    ssl_sock = _ssl_wrap_socket_impl(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
            "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 513, in wrap_socket\n",
            "    return self.sslsocket_class._create(\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1071, in _create\n",
            "    self.do_handshake()\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
            "    self._sslobj.do_handshake()\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 440, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 550, in increment\n",
            "    raise six.reraise(type(error), error, _stacktrace)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/packages/six.py\", line 769, in reraise\n",
            "    raise value.with_traceback(tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
            "    conn.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 419, in connect\n",
            "    self.sock = ssl_wrap_socket(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
            "    ssl_sock = _ssl_wrap_socket_impl(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
            "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 513, in wrap_socket\n",
            "    return self.sslsocket_class._create(\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1071, in _create\n",
            "    self.do_handshake()\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
            "    self._sslobj.do_handshake()\n",
            "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-17-ef5c5efd23d6>\", line 6, in get_extended_datails\n",
            "    movie_main_page = requests.get(movie_page_url, headers=headers)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 75, in get\n",
            "    return request('get', url, params=params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 61, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 529, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 645, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 501, in send\n",
            "    raise ConnectionError(err, request=request)\n",
            "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run number: 1200. basic_data_collected: 1199. extended_data_collected: 1199. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 1400. basic_data_collected: 1399. extended_data_collected: 1399. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "No Writer found for movie North Hollywood. Url: https://www.imdb.com/title/tt11165716/?ref_=adv_li_i\n",
            "Could not find a value for: CN¥ in CN¥150,000,000\n",
            "\n",
            "Run number: 1600. basic_data_collected: 1599. extended_data_collected: 1599. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 1800. basic_data_collected: 1799. extended_data_collected: 1799. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "No Writer found for movie Happier Than Ever: A Love Letter to Los Angeles. Url: https://www.imdb.com/title/tt15094392/?ref_=adv_li_i\n",
            "\n",
            "Run number: 2000. basic_data_collected: 1999. extended_data_collected: 1999. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "Could not find a value for: IDR in IDR 70,500,000,000\n",
            "No Writer found for movie Wunderland. Url: https://www.imdb.com/title/tt5815078/?ref_=adv_li_i\n",
            "£200,000 GBP 200000.0 https://openexchangerates.org/api/latest.json?app_id=ac63294868f6455a91a128e22f4d9f35&symbols=GBP\n",
            "<Response [200]>\n",
            "£200,000 GBP = 251617 USD\n",
            "\n",
            "Run number: 2200. basic_data_collected: 2199. extended_data_collected: 2199. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "No Writer found for movie Escape the Undertaker. Url: https://www.imdb.com/title/tt15387782/?ref_=adv_li_i\n",
            "No Writer found for movie Metallica & San Francisco Symphony - S&M2. Url: https://www.imdb.com/title/tt10765852/?ref_=adv_li_i\n",
            "\n",
            "Run number: 2400. basic_data_collected: 2399. extended_data_collected: 2399. basic_data_skipped: 0. extended_data_skipped: 0\n",
            "\n",
            "Run number: 2401. \n",
            "basic_data_collected: 2400. \n",
            "extended_data_collected: 2400. \n",
            "basic_data_skipped: 0. \n",
            "extended_data_skipped: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.DataFrame(total_movie_dataset).T\n",
        "movie_dataset.to_csv(movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "\n",
        "movie_dataset.head(5)"
      ],
      "metadata": {
        "id": "1zPMKZlwevQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "b8fa8e2c-12c2-4b1a-bc82-d473f1f334e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           __SuccsefullyCollectBasicDetails  \\\n",
              "tt1630029                              True   \n",
              "tt6710474                              True   \n",
              "tt9764362                              True   \n",
              "tt7888964                              True   \n",
              "tt10640346                             True   \n",
              "\n",
              "           __SuccsefullyCollectExtandedDetails  \\\n",
              "tt1630029                                 True   \n",
              "tt6710474                                 True   \n",
              "tt9764362                                 True   \n",
              "tt7888964                                 True   \n",
              "tt10640346                                True   \n",
              "\n",
              "                                   movie_name  \\\n",
              "tt1630029            Avatar: The Way of Water   \n",
              "tt6710474   Everything Everywhere All at Once   \n",
              "tt9764362                            The Menu   \n",
              "tt7888964                              Nobody   \n",
              "tt10640346                            Babylon   \n",
              "\n",
              "                                               movie_page_url movie_place  \\\n",
              "tt1630029   https://www.imdb.com/title/tt1630029/?ref_=adv...           1   \n",
              "tt6710474   https://www.imdb.com/title/tt6710474/?ref_=adv...           2   \n",
              "tt9764362   https://www.imdb.com/title/tt9764362/?ref_=adv...           3   \n",
              "tt7888964   https://www.imdb.com/title/tt7888964/?ref_=adv...           4   \n",
              "tt10640346  https://www.imdb.com/title/tt10640346/?ref_=ad...           5   \n",
              "\n",
              "              movie_id                                    movie_thubmnail  \\\n",
              "tt1630029    tt1630029  https://m.media-amazon.com/images/S/sash/4Fyxw...   \n",
              "tt6710474    tt6710474  https://m.media-amazon.com/images/S/sash/4Fyxw...   \n",
              "tt9764362    tt9764362  https://m.media-amazon.com/images/S/sash/4Fyxw...   \n",
              "tt7888964    tt7888964  https://m.media-amazon.com/images/S/sash/4Fyxw...   \n",
              "tt10640346  tt10640346  https://m.media-amazon.com/images/S/sash/4Fyxw...   \n",
              "\n",
              "           movie_metascore                                  movie_description  \\\n",
              "tt1630029               67  Jake Sully lives with his newfound family form...   \n",
              "tt6710474               81  A middle-aged Chinese immigrant is swept up in...   \n",
              "tt9764362               71  A young couple travels to a remote island to e...   \n",
              "tt7888964               64  A docile family man slowly reveals his true ch...   \n",
              "tt10640346              60  A tale of outsized ambition and outrageous exc...   \n",
              "\n",
              "           runtime_min  ... cast_count_music_department  \\\n",
              "tt1630029          192  ...                          74   \n",
              "tt6710474          139  ...                          45   \n",
              "tt9764362          107  ...                          11   \n",
              "tt7888964           92  ...                          15   \n",
              "tt10640346         189  ...                          38   \n",
              "\n",
              "           cast_count_script_department cast_count_transportation_department  \\\n",
              "tt1630029                             7                                   10   \n",
              "tt6710474                             4                                   27   \n",
              "tt9764362                           NaN                                   10   \n",
              "tt7888964                             2                                    9   \n",
              "tt10640346                            2                                   13   \n",
              "\n",
              "           cast_count_miscellaneous cast_count_thanks   Director_2_name  \\\n",
              "tt1630029                       140                 6               NaN   \n",
              "tt6710474                       104                58  Daniel Scheinert   \n",
              "tt9764362                        71               NaN               NaN   \n",
              "tt7888964                        58                 6               NaN   \n",
              "tt10640346                       89                 1               NaN   \n",
              "\n",
              "           Director_2_imdb_id cast_count_production_department  \\\n",
              "tt1630029                 NaN                              NaN   \n",
              "tt6710474           nm3215397                              NaN   \n",
              "tt9764362                 NaN                              NaN   \n",
              "tt7888964                 NaN                              NaN   \n",
              "tt10640346                NaN                              NaN   \n",
              "\n",
              "           Director_3_name Director_3_imdb_id  \n",
              "tt1630029              NaN                NaN  \n",
              "tt6710474              NaN                NaN  \n",
              "tt9764362              NaN                NaN  \n",
              "tt7888964              NaN                NaN  \n",
              "tt10640346             NaN                NaN  \n",
              "\n",
              "[5 rows x 83 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-240ce9e5-535e-42fc-b8aa-838718dc4224\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__SuccsefullyCollectBasicDetails</th>\n",
              "      <th>__SuccsefullyCollectExtandedDetails</th>\n",
              "      <th>movie_name</th>\n",
              "      <th>movie_page_url</th>\n",
              "      <th>movie_place</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>movie_thubmnail</th>\n",
              "      <th>movie_metascore</th>\n",
              "      <th>movie_description</th>\n",
              "      <th>runtime_min</th>\n",
              "      <th>...</th>\n",
              "      <th>cast_count_music_department</th>\n",
              "      <th>cast_count_script_department</th>\n",
              "      <th>cast_count_transportation_department</th>\n",
              "      <th>cast_count_miscellaneous</th>\n",
              "      <th>cast_count_thanks</th>\n",
              "      <th>Director_2_name</th>\n",
              "      <th>Director_2_imdb_id</th>\n",
              "      <th>cast_count_production_department</th>\n",
              "      <th>Director_3_name</th>\n",
              "      <th>Director_3_imdb_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tt1630029</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Avatar: The Way of Water</td>\n",
              "      <td>https://www.imdb.com/title/tt1630029/?ref_=adv...</td>\n",
              "      <td>1</td>\n",
              "      <td>tt1630029</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>67</td>\n",
              "      <td>Jake Sully lives with his newfound family form...</td>\n",
              "      <td>192</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>140</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tt6710474</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Everything Everywhere All at Once</td>\n",
              "      <td>https://www.imdb.com/title/tt6710474/?ref_=adv...</td>\n",
              "      <td>2</td>\n",
              "      <td>tt6710474</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>81</td>\n",
              "      <td>A middle-aged Chinese immigrant is swept up in...</td>\n",
              "      <td>139</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>104</td>\n",
              "      <td>58</td>\n",
              "      <td>Daniel Scheinert</td>\n",
              "      <td>nm3215397</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tt9764362</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>The Menu</td>\n",
              "      <td>https://www.imdb.com/title/tt9764362/?ref_=adv...</td>\n",
              "      <td>3</td>\n",
              "      <td>tt9764362</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>71</td>\n",
              "      <td>A young couple travels to a remote island to e...</td>\n",
              "      <td>107</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>71</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tt7888964</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Nobody</td>\n",
              "      <td>https://www.imdb.com/title/tt7888964/?ref_=adv...</td>\n",
              "      <td>4</td>\n",
              "      <td>tt7888964</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>64</td>\n",
              "      <td>A docile family man slowly reveals his true ch...</td>\n",
              "      <td>92</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tt10640346</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Babylon</td>\n",
              "      <td>https://www.imdb.com/title/tt10640346/?ref_=ad...</td>\n",
              "      <td>5</td>\n",
              "      <td>tt10640346</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>60</td>\n",
              "      <td>A tale of outsized ambition and outrageous exc...</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 83 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-240ce9e5-535e-42fc-b8aa-838718dc4224')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-240ce9e5-535e-42fc-b8aa-838718dc4224 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-240ce9e5-535e-42fc-b8aa-838718dc4224');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set actor variables"
      ],
      "metadata": {
        "id": "gmEs7UDA4sFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "import json\n",
        "from time import sleep\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import traceback"
      ],
      "metadata": {
        "id": "InfuPc6m64Yo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.read_csv('/content/drive/My Drive/Harvard HW/Course 4 - Final Project/total_movie_dataset.csv')\n",
        "movie_dataset.head(5)"
      ],
      "metadata": {
        "id": "mDjtqHinj9cA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "fb9626d1-08d5-4da4-9fd6-41c467a2817e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     movie_id  __SuccsefullyCollectBasicDetails  \\\n",
              "0   tt1630029                              True   \n",
              "1   tt6710474                              True   \n",
              "2   tt9764362                              True   \n",
              "3   tt7888964                              True   \n",
              "4  tt10640346                              True   \n",
              "\n",
              "   __SuccsefullyCollectExtandedDetails                         movie_name  \\\n",
              "0                                 True           Avatar: The Way of Water   \n",
              "1                                 True  Everything Everywhere All at Once   \n",
              "2                                 True                           The Menu   \n",
              "3                                 True                             Nobody   \n",
              "4                                 True                            Babylon   \n",
              "\n",
              "                                      movie_page_url movie_place  movie_id.1  \\\n",
              "0  https://www.imdb.com/title/tt1630029/?ref_=adv...           1   tt1630029   \n",
              "1  https://www.imdb.com/title/tt6710474/?ref_=adv...           2   tt6710474   \n",
              "2  https://www.imdb.com/title/tt9764362/?ref_=adv...           3   tt9764362   \n",
              "3  https://www.imdb.com/title/tt7888964/?ref_=adv...           4   tt7888964   \n",
              "4  https://www.imdb.com/title/tt10640346/?ref_=ad...           5  tt10640346   \n",
              "\n",
              "                                     movie_thubmnail  movie_metascore  \\\n",
              "0  https://m.media-amazon.com/images/S/sash/4Fyxw...             67.0   \n",
              "1  https://m.media-amazon.com/images/S/sash/4Fyxw...             81.0   \n",
              "2  https://m.media-amazon.com/images/S/sash/4Fyxw...             71.0   \n",
              "3  https://m.media-amazon.com/images/S/sash/4Fyxw...             64.0   \n",
              "4  https://m.media-amazon.com/images/S/sash/4Fyxw...             60.0   \n",
              "\n",
              "                                   movie_description  ...  \\\n",
              "0  Jake Sully lives with his newfound family form...  ...   \n",
              "1  A middle-aged Chinese immigrant is swept up in...  ...   \n",
              "2  A young couple travels to a remote island to e...  ...   \n",
              "3  A docile family man slowly reveals his true ch...  ...   \n",
              "4  A tale of outsized ambition and outrageous exc...  ...   \n",
              "\n",
              "   cast_count_music_department  cast_count_script_department  \\\n",
              "0                         74.0                           7.0   \n",
              "1                         45.0                           4.0   \n",
              "2                         11.0                           NaN   \n",
              "3                         15.0                           2.0   \n",
              "4                         38.0                           2.0   \n",
              "\n",
              "  cast_count_transportation_department cast_count_miscellaneous  \\\n",
              "0                                 10.0                    140.0   \n",
              "1                                 27.0                    104.0   \n",
              "2                                 10.0                     71.0   \n",
              "3                                  9.0                     58.0   \n",
              "4                                 13.0                     89.0   \n",
              "\n",
              "   cast_count_thanks   Director_2_name Director_2_imdb_id  \\\n",
              "0                6.0               NaN                NaN   \n",
              "1               58.0  Daniel Scheinert          nm3215397   \n",
              "2                NaN               NaN                NaN   \n",
              "3                6.0               NaN                NaN   \n",
              "4                1.0               NaN                NaN   \n",
              "\n",
              "  cast_count_production_department  Director_3_name Director_3_imdb_id  \n",
              "0                              NaN              NaN                NaN  \n",
              "1                              NaN              NaN                NaN  \n",
              "2                              NaN              NaN                NaN  \n",
              "3                              NaN              NaN                NaN  \n",
              "4                              NaN              NaN                NaN  \n",
              "\n",
              "[5 rows x 84 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3da950e9-6461-4c72-b7ab-4c2526138555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>__SuccsefullyCollectBasicDetails</th>\n",
              "      <th>__SuccsefullyCollectExtandedDetails</th>\n",
              "      <th>movie_name</th>\n",
              "      <th>movie_page_url</th>\n",
              "      <th>movie_place</th>\n",
              "      <th>movie_id.1</th>\n",
              "      <th>movie_thubmnail</th>\n",
              "      <th>movie_metascore</th>\n",
              "      <th>movie_description</th>\n",
              "      <th>...</th>\n",
              "      <th>cast_count_music_department</th>\n",
              "      <th>cast_count_script_department</th>\n",
              "      <th>cast_count_transportation_department</th>\n",
              "      <th>cast_count_miscellaneous</th>\n",
              "      <th>cast_count_thanks</th>\n",
              "      <th>Director_2_name</th>\n",
              "      <th>Director_2_imdb_id</th>\n",
              "      <th>cast_count_production_department</th>\n",
              "      <th>Director_3_name</th>\n",
              "      <th>Director_3_imdb_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt1630029</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Avatar: The Way of Water</td>\n",
              "      <td>https://www.imdb.com/title/tt1630029/?ref_=adv...</td>\n",
              "      <td>1</td>\n",
              "      <td>tt1630029</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>Jake Sully lives with his newfound family form...</td>\n",
              "      <td>...</td>\n",
              "      <td>74.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt6710474</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Everything Everywhere All at Once</td>\n",
              "      <td>https://www.imdb.com/title/tt6710474/?ref_=adv...</td>\n",
              "      <td>2</td>\n",
              "      <td>tt6710474</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>81.0</td>\n",
              "      <td>A middle-aged Chinese immigrant is swept up in...</td>\n",
              "      <td>...</td>\n",
              "      <td>45.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>Daniel Scheinert</td>\n",
              "      <td>nm3215397</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt9764362</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>The Menu</td>\n",
              "      <td>https://www.imdb.com/title/tt9764362/?ref_=adv...</td>\n",
              "      <td>3</td>\n",
              "      <td>tt9764362</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>A young couple travels to a remote island to e...</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt7888964</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Nobody</td>\n",
              "      <td>https://www.imdb.com/title/tt7888964/?ref_=adv...</td>\n",
              "      <td>4</td>\n",
              "      <td>tt7888964</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>A docile family man slowly reveals his true ch...</td>\n",
              "      <td>...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tt10640346</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Babylon</td>\n",
              "      <td>https://www.imdb.com/title/tt10640346/?ref_=ad...</td>\n",
              "      <td>5</td>\n",
              "      <td>tt10640346</td>\n",
              "      <td>https://m.media-amazon.com/images/S/sash/4Fyxw...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>A tale of outsized ambition and outrageous exc...</td>\n",
              "      <td>...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 84 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3da950e9-6461-4c72-b7ab-4c2526138555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3da950e9-6461-4c72-b7ab-4c2526138555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3da950e9-6461-4c72-b7ab-4c2526138555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Assume Gender"
      ],
      "metadata": {
        "id": "T0RJfRFee_ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assume_gender(artist_bio):\n",
        "  # Define the pronouns associated with each gender\n",
        "  male_pronouns = [\"he\", \"him\", \"his\", \"himself\",\"guy\",\"man\"]\n",
        "  female_pronouns = [\"she\", \"her\", \"hers\", \"herself\",\"girl\",\"woman\"]\n",
        "  nonbinary_pronouns = [\"themselves\",\"queer\",\"binary\",\"nonbinary\",\"non-binary\"]\n",
        "\n",
        "  is_openly_lgbt = False\n",
        "  lgbt_words = [\"gay\",\"lesbian\",\"gays\",\"lesbians\",\"lgbt\",\"lgbtq\",\"queer\",\"binary\",\"nonbinary\",\"non-binary\",\"genderfluid\"]\n",
        "\n",
        "  # Count the number of male and female pronouns in the bio\n",
        "  prnoun_count = {'Male':0, \"Female\":0, \"NonBinary\":0}\n",
        "\n",
        "  for word in artist_bio.lower().split():\n",
        "      if word in male_pronouns:\n",
        "          prnoun_count[\"Male\"] += 1\n",
        "      elif word in female_pronouns:\n",
        "          prnoun_count[\"Female\"] += 1\n",
        "      elif word in nonbinary_pronouns:\n",
        "          prnoun_count[\"NonBinary\"] += 1\n",
        "\n",
        "      if word in lgbt_words:\n",
        "        is_openly_lgbt = True\n",
        "\n",
        "  # Determine the actor's gender based on the pronoun count\n",
        "  sorted_d = {k: v for k, v in sorted(prnoun_count.items(), key=lambda item: item[1], reverse=True)}\n",
        "  Gender = next(iter(sorted_d))\n",
        "\n",
        "  if prnoun_count[Gender] == 0: # If no prnoune was found\n",
        "    Gender = \"Unknown\"\n",
        "\n",
        "  return Gender,is_openly_lgbt\n",
        "\n",
        "# Extract the bio text\n",
        "bio_text = \"\"\"Andy Samberg was born in Berkeley, California, to Marjorie (Marrow), a teacher, and Joe Samberg, a photographer. With Jorma Taccone and Akiva Schaffer, Samberg is one of three Los Angeles, California-based writer-performer-filmmakers--all childhood friends--dubbed The Lonely Island, whose short films were showcased on the popular untelevised television network show and website. Some of their popular shorts included The O.C. (2003) parody \"The 'Bu\" and their full-length pilot, \"Awesometown.\" They met Jimmy Fallon while writing for 2004 MTV Video Music Awards (2004), who then suggested that they audition for Saturday Night Live (1975). Andy was then cast as a featured performer, and Samberg's Lonely Island cohorts Jorma and Akiva were hired as writers for the show. The group's most notable contributions include The Lonely Island: Lazy Sunday (2005), The Lonely Island feat. Justin Timberlake: Dick in a Box (2006), and The Lonely Island Feat. T-Pain: I'm on a Boat (2009).\n",
        "\n",
        "Near the end of his first season of SNL, Andy started filming the lead role in the film Hot Rod (2007), the first major motion picture by the Lonely Island team, with the production support of Lorne Michaels.\n",
        "\n",
        "In 2012, after seven years of working on SNL, Samberg resigned from the show. He was originally not looking to join a television series as a regular cast member, but after seeing the script for Brooklyn Nine-Nine (2013), he couldn't pass it up. Andy plays Jake Peralta, the best detective in Brooklyn's 99th police precinct, who also happens to be the most immature. In 2013 Samberg received the Golden Globe for Best Actor - Television Series Musical or Comedy for his performance.\n",
        "\n",
        "In 2016, Andy starred in the pop music mockumentary Popstar: Never Stop Never Stopping (2016). Taccone and Schaffer co-starred in and co-directed the film.\n",
        "\n",
        "Samberg married singer-songwriter Joanna Newsom on 21 September, 2013, in Big Sur, California. In August 2017, they announced the birth of their baby daughter.\n",
        "\"\"\"\n",
        "assume_gender(bio_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muJrvn4spKx9",
        "outputId": "114a1daa-65ab-42ce-c9e1-bf706d866959"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Male', False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from dateutil import parser\n",
        "\n",
        "def extract_artist_age(date_string):\n",
        "  try:\n",
        "    # Parse the date string into a datetime object\n",
        "    date_obj = parser.parse(date_string)\n",
        "    # Check if the date is in the future, if so - Reduce 100 years\n",
        "    if date_obj.year > datetime.now().year:\n",
        "      date_obj = date_obj.replace(year=date_obj.year - 100)\n",
        "    #print(date_obj)\n",
        "    # Calculate the difference between the current date and the date of birth\n",
        "    age = relativedelta(datetime.now(), date_obj).years\n",
        "    # Return the age as an integer\n",
        "    return age\n",
        "  except:\n",
        "    #print(f\"Cannot extract age from value: {date_string}\")\n",
        "    return None\n",
        "\n",
        "print(extract_artist_age(\"11/25/1990\"))\n",
        "print(extract_artist_age(\"16-Apr-02\"))\n",
        "print(extract_artist_age(\"\"))"
      ],
      "metadata": {
        "id": "ocSn8KhHmzKf",
        "outputId": "fb5a1c5b-ee3e-4ddd-8d1a-b0b249f079a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "21\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Collect Rank"
      ],
      "metadata": {
        "id": "jiX7kUTS42-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_artist_rank(artist_page_soup,artist_dict):\n",
        "  artist_rank = artist_page_soup.find('span',{'class':'sc-d462a8ef-6 hOuQwM starmeter-current-rank'}).text.strip()\n",
        "\n",
        "  artist_dict['artist_rank'] = artist_rank\n",
        "  artist_dict['Is_5000'] = False\n",
        "  artist_dict['Is_500'] = False\n",
        "  artist_dict['Is_100'] = False\n",
        "  artist_dict['Is_10'] = False\n",
        "\n",
        "  if artist_rank.lower()!=\"see rank\":\n",
        "    if artist_rank==\"Top 5,000\":\n",
        "      artist_dict['Is_5000'] = True\n",
        "    elif artist_rank==\"Top 500\":\n",
        "      artist_dict['Is_500'] = True\n",
        "      artist_dict['Is_5000'] = True\n",
        "    else:\n",
        "      try:\n",
        "        rank = int(artist_rank)   # Convert the string to an integer\n",
        "        if rank <= 100:           # Check if the rank is within the top 100\n",
        "          artist_dict['Is_100'] = True\n",
        "          artist_dict['Is_500'] = True\n",
        "          artist_dict['Is_5000'] = True\n",
        "        if rank <= 10: \n",
        "          artist_dict['Is_10'] = True\n",
        "      except ValueError:\n",
        "        print(f\"Could not interpret value {artist_rank} for artist: {artist_dict['artist_imdb_id']}. Url: {artist_dict['artist_url']}\")\n",
        "\n",
        "artist_imdb_id = \"nm14727093\"\n",
        "artist_page = requests.get(f\"https://www.imdb.com/name/{artist_imdb_id}/\", headers=headers)\n",
        "artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "artist_dict = {}\n",
        "artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "artist_dict['artist_type'] = \"Director\"\n",
        "artist_dict['artist_url'] = artist_page\n",
        "collect_artist_rank(artist_page_soup,artist_dict)"
      ],
      "metadata": {
        "id": "-7vuUgpgqjXS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Artist awards"
      ],
      "metadata": {
        "id": "pbBKnsyCFirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_awards_info(awards_str):\n",
        "    wins = 0\n",
        "    nominations = 0\n",
        "    if awards_str:\n",
        "      parts = awards_str.split()\n",
        "      if \"wins\" in parts:\n",
        "          wins = int(parts[parts.index(\"wins\")-1])\n",
        "      elif \"win\" in parts:\n",
        "          wins = int(parts[parts.index(\"win\")-1])\n",
        "      if \"nominations\" in parts:\n",
        "          nominations = int(parts[parts.index(\"nominations\")-1])\n",
        "      elif \"nomination\" in parts:\n",
        "          nominations = int(parts[parts.index(\"nomination\")-1])\n",
        "    return (wins, nominations)\n",
        "\n",
        "print(get_awards_info(\"6 wins & 16 nominations total\"))\n",
        "print(get_awards_info(\"1 win & 1 nomination total\"))\n",
        "print(get_awards_info(\"6 wins total\"))\n",
        "print(get_awards_info(\"16 nominations total\"))\n",
        "print(get_awards_info('1 win & 3 nominations'))\n",
        "print(get_awards_info(\"\"))\n",
        "print(get_awards_info(None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAwyoxUHRNbH",
        "outputId": "ef4a00c6-0494-463c-bdba-1fdfc757da4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 16)\n",
            "(1, 1)\n",
            "(6, 0)\n",
            "(0, 16)\n",
            "(1, 3)\n",
            "(0, 0)\n",
            "(0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_artist_awards(artist_page_soup):\n",
        "  awards_dict = {}\n",
        "\n",
        "  awards = artist_page_soup.find('li',{'data-testid':'award_information'})\n",
        "  awards_prestige_wins = 0\n",
        "  awards_prestige_nominations = 0\n",
        "  awards_other_won = 0\n",
        "  awards_other_nominations = 0\n",
        "  \n",
        "  if awards!=None:\n",
        "\n",
        "    # Find prestige awards (Oscars, BEFTA, ect.)\n",
        "    prestige_awards = awards.find('a',{'aria-label':'See more awards and nominations'}).text\n",
        "    if prestige_awards!=\"Awards\":\n",
        "      awards_dict['awards_prestige_desc']  = prestige_awards\n",
        "      if \"Won\" in prestige_awards:\n",
        "        awards_prestige_wins = int(''.join(filter(str.isdigit, prestige_awards)))\n",
        "        \n",
        "      else:\n",
        "        awards_prestige_nominations = int(''.join(filter(str.isdigit, prestige_awards)))\n",
        "        \n",
        "    else:\n",
        "      awards_dict['awards_prestige']  = 0\n",
        "\n",
        "    # Find total awards\n",
        "    award_other = awards.find('span',{'class':'ipc-metadata-list-item__list-content-item'}).text\n",
        "    award_other_counts = get_awards_info(award_other)\n",
        "    awards_dict['award_other_desc'] = award_other\n",
        "    awards_other_won = award_other_counts[0]\n",
        "    awards_other_nominations = award_other_counts[1]\n",
        "\n",
        "  awards_dict['awards_prestige_wins']  = awards_prestige_wins\n",
        "  awards_dict['awards_prestige_nominations']  = awards_prestige_nominations\n",
        "  awards_dict['awards_other_won'] = awards_other_won\n",
        "  awards_dict['awards_other_nominations'] = awards_other_nominations\n",
        "\n",
        "  return awards_dict\n",
        "\n",
        "artist_imdb_id = \"nm0798646\"\n",
        "artist_page = requests.get(f\"https://www.imdb.com/name/{artist_imdb_id}/\", headers=headers)\n",
        "artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "artist_dict = {}\n",
        "artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "artist_dict['artist_type'] = \"Director\"\n",
        "artist_dict['artist_url'] = artist_page\n",
        "collect_artist_awards(artist_page_soup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mbxHcfhHQhN",
        "outputId": "480adc33-8d49-440d-e80b-0e2c9c89f0cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'awards_prestige': 0,\n",
              " 'award_other_desc': '1 win & 3 nominations',\n",
              " 'awards_prestige_wins': 0,\n",
              " 'awards_prestige_nominations': 0,\n",
              " 'awards_other_won': 1,\n",
              " 'awards_other_nominations': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Function: Extract artist info"
      ],
      "metadata": {
        "id": "v3ImIU1h49Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist_info(artist_imdb_id,col_name):\n",
        "  artist_dict = {}\n",
        "\n",
        "  artist_url_page = f\"{base_url}/name/{artist_imdb_id}\"\n",
        "  artist_dict['artist_imdb_id'] = artist_imdb_id\n",
        "  artist_dict['artist_type'] = col_name.split('_')[0]\n",
        "  artist_dict['artist_url'] = artist_url_page\n",
        "\n",
        "  try:\n",
        "    artist_page = requests.get(artist_url_page, headers=headers)\n",
        "    artist_page_soup = BeautifulSoup(artist_page.text, 'html.parser') \n",
        "\n",
        "    artist_name = artist_page_soup.find('h1',{'data-testid':'hero__pageTitle'}).find('span').text.strip()\n",
        "    artist_dict['artist_name'] = artist_name\n",
        "\n",
        "    if artist_page_soup.find('span', string=\"Born\") is not None:\n",
        "      artist_birthday = artist_page_soup.find('span',string=\"Born\").findNextSibling().text\n",
        "      artist_dict['artist_birthday'] = artist_birthday\n",
        "      artist_dict['artist_age'] = extract_artist_age(artist_birthday)\n",
        "      if artist_dict['artist_age'] == None:\n",
        "        print(f\"Unable to extract age for {artist_name}. Value: {artist_birthday} Url: {artist_url_page}\")\n",
        "      \n",
        "    artist_bio = artist_page_soup.find('div',{'class':'ipc-html-content-inner-div'})\n",
        "    \n",
        "    if artist_bio!=None:\n",
        "      artist_dict['artist_bio'] = artist_bio.text\n",
        "      artist_gender, is_openly_lgbt = assume_gender(artist_bio.text)\n",
        "    else:\n",
        "      artist_gender = \"Unknown\"\n",
        "      is_openly_lgbt = False\n",
        "\n",
        "    artist_dict['artist_gender'] = artist_gender\n",
        "    artist_dict['is_openly_lgbt'] = is_openly_lgbt\n",
        "\n",
        "    # Collect Rank\n",
        "    collect_artist_rank(artist_page_soup,artist_dict)\n",
        "    \n",
        "    # Collect Awards\n",
        "    awards_dict = collect_artist_awards(artist_page_soup)\n",
        "    artist_dict.update(awards_dict)\n",
        "\n",
        "    artist_title = artist_dict['artist_type']\n",
        "    if artist_title == \"Star\":\n",
        "      artist_title = \"Actress\" if artist_gender==\"Female\" else \"Actor\"\n",
        "\n",
        "    if artist_page_soup.find('h3',string=artist_title) is not None:\n",
        "      previous_work = artist_page_soup.find('h3',string=artist_title).find_next().find('li', string=\"Previous\")\n",
        "      if previous_work is not None:\n",
        "        previous_work = previous_work.find_next_sibling().text\n",
        "    elif artist_page_soup.find('li',string=\"Previous\") is not None:\n",
        "      previous_work = artist_page_soup.find('li',string=\"Previous\").find_next_sibling().text\n",
        "    else:\n",
        "      previous_work = 0\n",
        "      print(f\"Unable to get previous work for {artist_title}: {artist_name}. Url: {artist_url_page}\")\n",
        "      \n",
        "    artist_dict['previous_work'] = previous_work\n",
        "    artist_dict['__SuccsefullyCollectArtistDetails'] = True;\n",
        "\n",
        "    return artist_dict\n",
        "  except Exception as e:\n",
        "    print(f\"Failed extracting data for artist: {artist_imdb_id}. Url: {artist_url_page}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    artist_dict['__SuccsefullyCollectArtistDetails'] = False;\n",
        "\n",
        "artist_imdb_id = \"nm0767280\"\n",
        "col_name = \"Writer_2_imdb_id\"\n",
        "extract_artist_info(artist_imdb_id,col_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVjKflwUhi1E",
        "outputId": "9dced283-5b8b-47d6-a854-0c9cb85f1096"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'artist_imdb_id': 'nm0767280',\n",
              " 'artist_type': 'Writer',\n",
              " 'artist_url': 'https://www.imdb.com/name/nm0767280',\n",
              " 'artist_name': 'Dan Savage',\n",
              " 'artist_birthday': 'October 7, 1964',\n",
              " 'artist_age': 58,\n",
              " 'artist_bio': 'Dan Savage is a writer, TV personality, and activist best known for his\\npolitical and social commentary, as well as his honest approach to sex,\\nlove and relationships.Savage\\'s sex advice column, \"Savage Love,\" is syndicated in newspapers\\nand websites throughout the United States, Canada, Europe and Asia. He\\nis the Editorial Director of The Stranger, Seattle\\'s weekly alternative\\nnewspaper, and his writing has appeared in publications including The\\nNew York Times, The New York Times Magazine, GQ, Rolling Stone, The\\nOnion, and on Salon.com.Savage is also the author of several books, including: Savage Love; The\\nKid: What Happened When My Boyfriend and I Decided to Get Pregnant (PEN\\nWest Award for Creative Nonfiction, Lambda Literary Award for\\nNonfiction); Skipping Towards Gomorrah: The Seven Deadly Sins and the\\nPursuit of Happiness in America; and The Commitment: Love, Sex,\\nMarriage and My Family. In his latest bestselling book American Savage,\\nDan shares his insights on topics ranging from marriage, parenting and\\nthe gay agenda to the Catholic Church and sex education. It\\'s Dan\\'s\\nfrank and open discussions on such topics that had Publisher\\'s Weekly\\nrave why he is, \"America\\'s most in-your-face sex columnist and gay\\nrights activist.\"In addition to his appearances on CNN, MSNBC, and The Colbert Report,\\nSavage is a contributor to Ira Glass\\'s This American Life, and has\\nappeared on NPR\\'s Fresh Air with Terry Gross, HBO\\'s Real Time with Bill\\nMaher, and ABC\\'s 20/20. Savage is a frequent and popular speaker on\\ncollege campuses across the United States and Canada.In September 2010, Savage created a YouTube video with his husband\\nTerry Miller to inspire hope for LGBT young people facing harassment.\\nIn response to a number of students taking their own lives, Savage and\\nMiller wanted to create a personal message to let LGBT youth know that\\n\"it gets better\". Today, the It Gets Better Project has become a global movement, inspiring more\\nthan 50,000 It Gets Better videos viewed over 50 million times. The It\\nGets Better book, co-edited by Savage and Miller, was published in\\nMarch 2011, and an MTV documentary special, It Gets Better, aired in\\nFebruary 2012.Dan Savage grew up in Chicago and now lives in Seattle, Washington with\\nhis husband Terry Miller and their son, DJ.',\n",
              " 'artist_gender': 'Male',\n",
              " 'is_openly_lgbt': True,\n",
              " 'artist_rank': 'See rank',\n",
              " 'Is_5000': False,\n",
              " 'Is_500': False,\n",
              " 'Is_100': False,\n",
              " 'Is_10': False,\n",
              " 'awards_prestige_desc': 'Nominated for 1 Primetime Emmy',\n",
              " 'award_other_desc': '1 win & 2 nominations total',\n",
              " 'awards_prestige_wins': 0,\n",
              " 'awards_prestige_nominations': 1,\n",
              " 'awards_other_won': 1,\n",
              " 'awards_other_nominations': 2,\n",
              " 'previous_work': '3',\n",
              " '__SuccsefullyCollectArtistDetails': True}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Artist variables"
      ],
      "metadata": {
        "id": "YECMLiiB6Z42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artists_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/artists_dataset.csv\"\n",
        "if os.path.exists(artists_dataset_path):\n",
        "  artists_df = pd.read_csv(artists_dataset_path)\n",
        "  artists_list = artists_df.set_index('artist_imdb_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  artists_list = {}\n",
        "  artists_df = pd.DataFrame(artists_list)\n",
        "\n",
        "print(f\"artists_list contains {len(artists_list)} records\")\n",
        "artists_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "1cQdE9jBpMHE",
        "outputId": "404126a1-cb67-4a3e-ba43-12bce9fb3469"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artists_list contains 0 records\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b445f910-a8ba-47ec-9779-f1db38461209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b445f910-a8ba-47ec-9779-f1db38461209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b445f910-a8ba-47ec-9779-f1db38461209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b445f910-a8ba-47ec-9779-f1db38461209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Collect Artists"
      ],
      "metadata": {
        "id": "Q4R6_7X-5DvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_cols = [col for col in movie_dataset.columns if \"imdb_id\" in col]\n",
        "\n",
        "artists_skipped = 0\n",
        "artists_collected = 0\n",
        "artist_count = 1\n",
        "for i, row in movie_dataset.iterrows():\n",
        "  for col_name in artist_cols:\n",
        "    artist_dict = {'artist_collected':False}\n",
        "    artist_imdb_id = row[col_name]\n",
        "    if type(artist_imdb_id) != float:\n",
        "      if artist_imdb_id in artists_list.keys() and artists_list[artist_imdb_id]['artist_collected']==True:\n",
        "        artist_dict = artists_list[artist_imdb_id]\n",
        "        artist_dict['artist_collected']=True\n",
        "        artists_skipped += 1\n",
        "      else:\n",
        "        artist_output = extract_artist_info(artist_imdb_id,col_name)\n",
        "        if artist_output!=None:\n",
        "          artist_dict.update(artist_output)\n",
        "          artist_dict['artist_collected']=True\n",
        "        artists_collected += 1 \n",
        "        sleep(0.1)\n",
        "\n",
        "      artists_list[artist_imdb_id] = artist_dict\n",
        "      artist_count += 1\n",
        "      if artist_count%200 == 0:\n",
        "        artist_dataset = pd.DataFrame(artists_list).T\n",
        "        artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "        print(f\"\\nSaving progress. Run {artist_count} for movie {i}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")\n",
        "\n",
        "artist_dataset = pd.DataFrame(artists_list).T\n",
        "artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "print(f\"\\n\\nFinished process. Total: {artist_count}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")"
      ],
      "metadata": {
        "id": "3ILsPPc9dUkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb54abbb-ff49-4f56-e878-01a4fcabbc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to extract age for Tommy Swerdlow. Value: c. 1962 Url: https://www.imdb.com/name/nm0842476\n",
            "Unable to extract age for Jon Spaihts. Value: New York City, New York, USA Url: https://www.imdb.com/name/nm3123612\n",
            "\n",
            "Saving progress. Run 200 for movie 33. artists_collected:167. artists_skipped:32\n",
            "Unable to extract age for Dana Stevens. Value: Whittier, California, USA Url: https://www.imdb.com/name/nm0828342\n",
            "\n",
            "Saving progress. Run 400 for movie 65. artists_collected:321. artists_skipped:78\n",
            "\n",
            "Saving progress. Run 600 for movie 95. artists_collected:468. artists_skipped:131\n",
            "Unable to extract age for Jonathan Roberts. Value: Boston, Massachusetts, USA Url: https://www.imdb.com/name/nm0731271\n",
            "Unable to extract age for Adele Lim. Value: Malaysia Url: https://www.imdb.com/name/nm1004604\n",
            "\n",
            "Saving progress. Run 800 for movie 125. artists_collected:624. artists_skipped:175\n",
            "Unable to extract age for Katherine Laheen. Value: Dublin, Ireland Url: https://www.imdb.com/name/nm11621216\n",
            "\n",
            "Saving progress. Run 1000 for movie 156. artists_collected:760. artists_skipped:239\n",
            "Unable to extract age for Isabella Laughland. Value: England, UK Url: https://www.imdb.com/name/nm2877285\n",
            "\n",
            "Saving progress. Run 1200 for movie 188. artists_collected:897. artists_skipped:302\n",
            "\n",
            "Saving progress. Run 1400 for movie 221. artists_collected:1029. artists_skipped:370\n",
            "Unable to extract age for Sharon Soboil. Value: Riverside, California, USA Url: https://www.imdb.com/name/nm0757267\n",
            "\n",
            "Saving progress. Run 1600 for movie 253. artists_collected:1170. artists_skipped:429\n",
            "Unable to extract age for J. David Stem. Value: Durham, North Carolina, USA Url: https://www.imdb.com/name/nm0826425\n",
            "\n",
            "Saving progress. Run 1800 for movie 285. artists_collected:1291. artists_skipped:508\n",
            "Unable to extract age for Kate Arrington. Value: Plainfield, New Jersey, USA Url: https://www.imdb.com/name/nm1667066\n",
            "Unable to extract age for George Young. Value: February 29 Url: https://www.imdb.com/name/nm2965226\n",
            "\n",
            "Saving progress. Run 2000 for movie 316. artists_collected:1418. artists_skipped:581\n",
            "Unable to extract age for Charles Leavitt. Value: Pittsburgh, Pennsylvania, USA Url: https://www.imdb.com/name/nm0495378\n",
            "Unable to extract age for Claire Scanlon. Value: Chicago, Illinois, USA Url: https://www.imdb.com/name/nm0768957\n",
            "\n",
            "Saving progress. Run 2200 for movie 349. artists_collected:1541. artists_skipped:658\n",
            "\n",
            "Saving progress. Run 2400 for movie 383. artists_collected:1669. artists_skipped:730\n",
            "Unable to get previous work for Actress: Sarah Yarkin. Url: https://www.imdb.com/name/nm4712111\n",
            "Unable to extract age for Cara Gee. Value: Calgary, Alberta, Canada Url: https://www.imdb.com/name/nm4446254\n",
            "Unable to extract age for Brady Noon. Value: Forked River, New Jersey, USA Url: https://www.imdb.com/name/nm4054776\n",
            "\n",
            "Saving progress. Run 2600 for movie 414. artists_collected:1791. artists_skipped:808\n",
            "Unable to extract age for John Swab. Value: Tulsa, Oklahoma, USA Url: https://www.imdb.com/name/nm6461537\n",
            "\n",
            "Saving progress. Run 2800 for movie 447. artists_collected:1922. artists_skipped:877\n",
            "Unable to extract age for Steven S. DeKnight. Value: Millville, New Jersey, USA Url: https://www.imdb.com/name/nm0215299\n",
            "Unable to extract age for Sara Bernstein. Value: Chico, California, USA Url: https://www.imdb.com/name/nm0077135\n",
            "Unable to extract age for Kevin Costello. Value: Oklahoma, USA Url: https://www.imdb.com/name/nm8213708\n",
            "Unable to extract age for John Rogers. Value: Worcester, Massachusetts, USA Url: https://www.imdb.com/name/nm0736966\n",
            "\n",
            "Saving progress. Run 3000 for movie 477. artists_collected:2047. artists_skipped:952\n",
            "\n",
            "Saving progress. Run 3200 for movie 510. artists_collected:2175. artists_skipped:1024\n",
            "Unable to extract age for Brian Gunn. Value: St. Louis, Missouri, USA Url: https://www.imdb.com/name/nm0348160\n",
            "Unable to extract age for Mark Gunn. Value: St. Louis, Missouri, USA Url: https://www.imdb.com/name/nm0348208\n",
            "Unable to extract age for Michael Mailer. Value: c. 1964 Url: https://www.imdb.com/name/nm0537550\n",
            "\n",
            "Saving progress. Run 3400 for movie 543. artists_collected:2296. artists_skipped:1103\n",
            "Unable to extract age for David Ian McKendry. Value: Virginia Beach, Virginia, USA Url: https://www.imdb.com/name/nm4503561\n",
            "Unable to extract age for Fodhla Cronin O'Reilly. Value: Ireland Url: https://www.imdb.com/name/nm2154065\n",
            "\n",
            "Saving progress. Run 3600 for movie 575. artists_collected:2410. artists_skipped:1189\n",
            "Unable to extract age for Jeffrey Thomas. Value: Wales, UK Url: https://www.imdb.com/name/nm0859005\n",
            "\n",
            "Saving progress. Run 3800 for movie 608. artists_collected:2537. artists_skipped:1262\n",
            "Unable to extract age for Scott Teems. Value: Lilburn, Georgia, USA Url: https://www.imdb.com/name/nm1802374\n",
            "Unable to extract age for Barry W. Blaustein. Value: c. 1955 Url: https://www.imdb.com/name/nm0087904\n",
            "\n",
            "Saving progress. Run 4000 for movie 642. artists_collected:2654. artists_skipped:1345\n",
            "Unable to extract age for Jamison Jones. Value: Detroit, Michigan, USA Url: https://www.imdb.com/name/nm0428309\n",
            "\n",
            "Saving progress. Run 4200 for movie 676. artists_collected:2775. artists_skipped:1424\n",
            "Unable to extract age for Marcus Thomas. Value: Brussels, Belgium Url: https://www.imdb.com/name/nm0859197\n",
            "\n",
            "Saving progress. Run 4400 for movie 707. artists_collected:2903. artists_skipped:1496\n",
            "Unable to extract age for Tara Westwood. Value: Manitoba, Canada Url: https://www.imdb.com/name/nm0923105\n",
            "\n",
            "Saving progress. Run 4600 for movie 740. artists_collected:3035. artists_skipped:1564\n",
            "\n",
            "Saving progress. Run 4800 for movie 773. artists_collected:3137. artists_skipped:1662\n",
            "\n",
            "Saving progress. Run 5000 for movie 807. artists_collected:3249. artists_skipped:1750\n",
            "\n",
            "Saving progress. Run 5200 for movie 840. artists_collected:3379. artists_skipped:1820\n",
            "\n",
            "Saving progress. Run 5400 for movie 874. artists_collected:3500. artists_skipped:1899\n",
            "\n",
            "Saving progress. Run 5600 for movie 908. artists_collected:3610. artists_skipped:1989\n",
            "Unable to extract age for Lindsay Watson. Value: Kula, Hawaii Url: https://www.imdb.com/name/nm7341118\n",
            "Unable to get previous work for Actress: Jesse LaTourette. Url: https://www.imdb.com/name/nm6922685\n",
            "Unable to extract age for Steve Galluccio. Value: Montréal, Québec, Canada Url: https://www.imdb.com/name/nm1241330\n",
            "\n",
            "Saving progress. Run 5800 for movie 942. artists_collected:3737. artists_skipped:2062\n",
            "Unable to extract age for Christopher Borrelli. Value: Needham, Massachusetts, USA Url: https://www.imdb.com/name/nm0096319\n",
            "Unable to extract age for Jesse Armstrong. Value: Oswestry, Shropshire, England, UK Url: https://www.imdb.com/name/nm1104036\n",
            "Unable to extract age for Bess Wohl. Value: Brooklyn, New York, USA Url: https://www.imdb.com/name/nm0937384\n",
            "\n",
            "Saving progress. Run 6000 for movie 974. artists_collected:3834. artists_skipped:2165\n",
            "Unable to extract age for Michael Spierig. Value: Germany Url: https://www.imdb.com/name/nm1294961\n",
            "Unable to extract age for Peter Spierig. Value: Germany Url: https://www.imdb.com/name/nm1294962\n",
            "\n",
            "Saving progress. Run 6200 for movie 1008. artists_collected:3941. artists_skipped:2258\n",
            "Unable to extract age for Peter Macdissi. Value: Beirut, Lebanon Url: https://www.imdb.com/name/nm0531589\n",
            "\n",
            "Saving progress. Run 6400 for movie 1041. artists_collected:4061. artists_skipped:2338\n",
            "Unable to extract age for Director X.. Value: Toronto, Ontario, Canada Url: https://www.imdb.com/name/nm1962311\n",
            "Unable to extract age for Clay Jeter. Value: Clarksville, Tennessee, USA Url: https://www.imdb.com/name/nm0422316\n",
            "\n",
            "Saving progress. Run 6600 for movie 1074. artists_collected:4181. artists_skipped:2418\n",
            "\n",
            "Saving progress. Run 6800 for movie 1108. artists_collected:4291. artists_skipped:2508\n",
            "Unable to extract age for Jamie Bernadette. Value: Kankakee, Illinois, USA Url: https://www.imdb.com/name/nm2584117\n",
            "Unable to extract age for Chris White. Value: New York City, New York, USA Url: https://www.imdb.com/name/nm1184214\n",
            "\n",
            "Saving progress. Run 7000 for movie 1145. artists_collected:4414. artists_skipped:2585\n",
            "\n",
            "Saving progress. Run 7200 for movie 1178. artists_collected:4535. artists_skipped:2664\n",
            "Unable to extract age for Steve Bloom. Value: Buffalo, New York, USA Url: https://www.imdb.com/name/nm0089237\n",
            "Unable to extract age for Charles Stone III. Value: c. 1966 Url: https://www.imdb.com/name/nm0831690\n",
            "Unable to extract age for Tom Anniko. Value: Winnipeg, Manitoba, Canada Url: https://www.imdb.com/name/nm0030394\n",
            "Unable to extract age for Olivia Jewson. Value: UK Url: https://www.imdb.com/name/nm3386634\n",
            "Unable to extract age for Joel H. Cohen. Value: Calgary, Alberta, Canada Url: https://www.imdb.com/name/nm1121389\n",
            "\n",
            "Saving progress. Run 7400 for movie 1212. artists_collected:4653. artists_skipped:2746\n",
            "Unable to extract age for Marcel Sawicki. Value: Ostrzeszów, Wielkopolskie, Poland Url: https://www.imdb.com/name/nm3006353\n",
            "Unable to extract age for Stephen Kendrick. Value: Athens, Georgia, USA Url: https://www.imdb.com/name/nm1726854\n",
            "Unable to extract age for David Aaron Cohen. Value: Chicago, Illinois, USA Url: https://www.imdb.com/name/nm0169173\n",
            "\n",
            "Saving progress. Run 7600 for movie 1246. artists_collected:4770. artists_skipped:2829\n",
            "Unable to extract age for Danishka Esterhazy. Value: Winnipeg, Manitoba, Canada Url: https://www.imdb.com/name/nm0261629\n",
            "\n",
            "Saving progress. Run 7800 for movie 1279. artists_collected:4901. artists_skipped:2898\n",
            "\n",
            "Saving progress. Run 8000 for movie 1312. artists_collected:5019. artists_skipped:2980\n",
            "\n",
            "Saving progress. Run 8200 for movie 1346. artists_collected:5126. artists_skipped:3073\n",
            "Unable to extract age for Gary Yates. Value: Montréal, Québec, Canada Url: https://www.imdb.com/name/nm0946750\n",
            "Unable to extract age for Brendan Penny. Value: Ottawa, Ontario, Canada Url: https://www.imdb.com/name/nm1638242\n",
            "Unable to extract age for Alex Essoe. Value: Dhahran, Saudi Arabia Url: https://www.imdb.com/name/nm3012273\n",
            "\n",
            "Saving progress. Run 8400 for movie 1379. artists_collected:5256. artists_skipped:3143\n",
            "Unable to extract age for Ben Schnetzer. Value: New York, New York, USA Url: https://www.imdb.com/name/nm3115493\n",
            "Unable to extract age for Alex Ranarivelo. Value: Saint-Jean-d'Angely, France Url: https://www.imdb.com/name/nm1156199\n",
            "Unable to extract age for Taryn O'Neill. Value: Vancouver, British Columbia, Canada Url: https://www.imdb.com/name/nm0993644\n",
            "\n",
            "Saving progress. Run 8600 for movie 1412. artists_collected:5375. artists_skipped:3224\n",
            "\n",
            "Saving progress. Run 8800 for movie 1446. artists_collected:5497. artists_skipped:3302\n",
            "\n",
            "Saving progress. Run 9000 for movie 1481. artists_collected:5609. artists_skipped:3390\n",
            "\n",
            "Saving progress. Run 9200 for movie 1513. artists_collected:5725. artists_skipped:3474\n",
            "Unable to extract age for Jen McGowan. Value: Washington, District of Columbia, USA Url: https://www.imdb.com/name/nm0569653\n",
            "Unable to extract age for Joe Lynch. Value: Long Island, New York, USA Url: https://www.imdb.com/name/nm1362570\n",
            "\n",
            "Saving progress. Run 9400 for movie 1547. artists_collected:5840. artists_skipped:3559\n",
            "Unable to extract age for Samantha McIntyre. Value: Dallas, Texas, USA Url: https://www.imdb.com/name/nm1916239\n",
            "\n",
            "Saving progress. Run 9600 for movie 1581. artists_collected:5956. artists_skipped:3643\n",
            "Unable to extract age for Ben Stassen. Value: Belgium Url: https://www.imdb.com/name/nm0823721\n",
            "\n",
            "Saving progress. Run 9800 for movie 1615. artists_collected:6067. artists_skipped:3732\n",
            "Unable to extract age for Paul Tarantino. Value: New Jersey, USA Url: https://www.imdb.com/name/nm0850227\n",
            "Unable to extract age for Kelsey Carlisle. Value: Indianapolis, Indiana, USA Url: https://www.imdb.com/name/nm6219464\n",
            "Unable to extract age for Jody Hill. Value: North Carolina, USA Url: https://www.imdb.com/name/nm2095817\n",
            "Unable to extract age for Sherri Eakin. Value: Metairie, Louisiana, USA Url: https://www.imdb.com/name/nm4748817\n",
            "\n",
            "Saving progress. Run 10000 for movie 1648. artists_collected:6175. artists_skipped:3824\n",
            "Unable to extract age for John Altschuler. Value: c. 1963 Url: https://www.imdb.com/name/nm1014365\n",
            "Unable to extract age for Dave Krinsky. Value: c. 1963 Url: https://www.imdb.com/name/nm1015106\n",
            "Unable to extract age for Emma Greenwell. Value: Greenwich, Connecticut, USA Url: https://www.imdb.com/name/nm4563896\n",
            "Unable to extract age for Howard Klausner. Value: c. 1960 Url: https://www.imdb.com/name/nm0458439\n",
            "Unable to extract age for Megan Alexander. Value: Seattle, Washington, USA Url: https://www.imdb.com/name/nm5287560\n",
            "\n",
            "Saving progress. Run 10200 for movie 1683. artists_collected:6304. artists_skipped:3895\n",
            "\n",
            "Saving progress. Run 10400 for movie 1718. artists_collected:6417. artists_skipped:3982\n",
            "Unable to extract age for Ken Hixon. Value: Indiana, USA Url: https://www.imdb.com/name/nm0387025\n",
            "\n",
            "Saving progress. Run 10600 for movie 1751. artists_collected:6545. artists_skipped:4054\n",
            "Unable to extract age for Ezra Buzzington. Value: Muncie, Indiana, USA Url: https://www.imdb.com/name/nm0125653\n",
            "\n",
            "Saving progress. Run 10800 for movie 1786. artists_collected:6653. artists_skipped:4146\n",
            "Unable to extract age for Eitan Gorlin. Value: c. 1969 Url: https://www.imdb.com/name/nm1148912\n",
            "\n",
            "Saving progress. Run 11000 for movie 1820. artists_collected:6768. artists_skipped:4231\n",
            "Unable to get previous work for Actor: Tordy Clark. Url: https://www.imdb.com/name/nm0164577\n",
            "Unable to extract age for Rob Pallatina. Value: Walsall, West Midlands, England, UK Url: https://www.imdb.com/name/nm3973341\n",
            "\n",
            "Saving progress. Run 11200 for movie 1855. artists_collected:6882. artists_skipped:4317\n",
            "\n",
            "Saving progress. Run 11400 for movie 1889. artists_collected:7005. artists_skipped:4394\n",
            "Unable to extract age for Hannah Kasulka. Value: Georgia, USA Url: https://www.imdb.com/name/nm2453033\n",
            "Unable to extract age for Swati Das. Value: India Url: https://www.imdb.com/name/nm6372501\n",
            "\n",
            "Saving progress. Run 11600 for movie 1923. artists_collected:7127. artists_skipped:4472\n",
            "Unable to extract age for Wych Kaosayananda. Value: c. 1974 Url: https://www.imdb.com/name/nm1126346\n",
            "\n",
            "Saving progress. Run 11800 for movie 1957. artists_collected:7250. artists_skipped:4549\n",
            "\n",
            "Saving progress. Run 12000 for movie 1992. artists_collected:7381. artists_skipped:4618\n",
            "\n",
            "Saving progress. Run 12200 for movie 2028. artists_collected:7511. artists_skipped:4688\n",
            "Unable to extract age for Kestrin Pantera. Value: USA Url: https://www.imdb.com/name/nm1580045\n",
            "Unable to extract age for Lora Martinez-Cunningham. Value: Albuquerque, New Mexico, USA Url: https://www.imdb.com/name/nm1254942\n",
            "Unable to extract age for Richard Lasser. Value: Yakima, Washington, USA Url: https://www.imdb.com/name/nm1103773\n",
            "\n",
            "Saving progress. Run 12400 for movie 2061. artists_collected:7640. artists_skipped:4759\n",
            "Unable to extract age for Tzi Ma. Value: Hong Kong, China Url: https://www.imdb.com/name/nm0002245\n",
            "\n",
            "Saving progress. Run 12600 for movie 2097. artists_collected:7761. artists_skipped:4838\n",
            "Unable to extract age for Ben Hernandez Bray. Value: San Fernando, California, USA Url: https://www.imdb.com/name/nm0004554\n",
            "Unable to extract age for John Littlefield. Value: July 8, 19?? Url: https://www.imdb.com/name/nm0514704\n",
            "Unable to extract age for Aimee Stolte. Value: Buffalo, New York, USA Url: https://www.imdb.com/name/nm6116282\n",
            "\n",
            "Saving progress. Run 12800 for movie 2132. artists_collected:7879. artists_skipped:4920\n",
            "Unable to extract age for Gia Skova. Value: Saratov, Russia Url: https://www.imdb.com/name/nm4341268\n",
            "\n",
            "Saving progress. Run 13000 for movie 2166. artists_collected:8010. artists_skipped:4989\n",
            "Unable to extract age for Victoria De Mare. Value: Wilmington, Delaware, USA Url: https://www.imdb.com/name/nm1389064\n",
            "\n",
            "Saving progress. Run 13200 for movie 2202. artists_collected:8136. artists_skipped:5063\n",
            "Unable to extract age for Nicola Lambo. Value: Jamaica, West Indies Url: https://www.imdb.com/name/nm2068832\n",
            "Unable to extract age for Scott Jeffrey. Value: Essex, England, UK Url: https://www.imdb.com/name/nm8448178\n",
            "\n",
            "Saving progress. Run 13400 for movie 2237. artists_collected:8268. artists_skipped:5131\n",
            "Unable to extract age for Marama Corlett. Value: Valletta, Malta Url: https://www.imdb.com/name/nm3744128\n",
            "\n",
            "Saving progress. Run 13600 for movie 2271. artists_collected:8403. artists_skipped:5196\n",
            "Unable to extract age for Vera VanGuard. Value: Moscow, Russian SFSR, USSR [now Russia] Url: https://www.imdb.com/name/nm1475801\n",
            "\n",
            "Saving progress. Run 13800 for movie 2306. artists_collected:8540. artists_skipped:5259\n",
            "Unable to extract age for Slick Woods. Value: Minneapolis, Minnesota, USA Url: https://www.imdb.com/name/nm9239853\n",
            "Unable to extract age for Wayne Isham. Value: c. 1958 Url: https://www.imdb.com/name/nm0410864\n",
            "Unable to extract age for Keith Machekanyanga. Value: Bulawayo, Zimbabwe Url: https://www.imdb.com/name/nm8176857\n",
            "\n",
            "Saving progress. Run 14000 for movie 2340. artists_collected:8689. artists_skipped:5310\n",
            "Unable to extract age for Isaac C. Singleton Jr.. Value: Melbourne, Florida, USA Url: https://www.imdb.com/name/nm0802280\n",
            "Unable to extract age for Michael Eklund. Value: July 31, 19?? Url: https://www.imdb.com/name/nm1002664\n",
            "Unable to extract age for J. Horton. Value: Fort Wayne, Indiana, USA Url: https://www.imdb.com/name/nm1862032\n",
            "Unable to extract age for Tammy Pescatelli. Value: Cleveland, Ohio, USA Url: https://www.imdb.com/name/nm1018708\n",
            "\n",
            "Saving progress. Run 14200 for movie 2375. artists_collected:8824. artists_skipped:5375\n",
            "Unable to extract age for Megan Hensley. Value: Des Moines, Iowa, USA Url: https://www.imdb.com/name/nm3655078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "artist_dataset.head(5)"
      ],
      "metadata": {
        "id": "-UoBsJHZ03SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build final dataset"
      ],
      "metadata": {
        "id": "_b0WUdg-jWDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go over the movie_dataset and convert the data to a manageable format"
      ],
      "metadata": {
        "id": "_6DUIv-EktM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/imdb_dataset.csv\"\n",
        "if os.path.exists(imdb_dataset_path):\n",
        "  imdb_df = pd.read_csv(imdb_dataset_path)\n",
        "  imdb_dict = imdb_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  imdb_dict = {}\n",
        "  imdb_df = pd.DataFrame(imdb_dict)\n",
        "\n",
        "print(f\"imdb_dict contains {len(imdb_dict)} records\")\n",
        "imdb_df.head(3)"
      ],
      "metadata": {
        "id": "YGESu4IYjViK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset.head(3).T"
      ],
      "metadata": {
        "id": "FVX2oaFQk9uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Convert string to number"
      ],
      "metadata": {
        "id": "rByBbY4inXha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_numbers(num_string):\n",
        "  try:\n",
        "    if not num_string:\n",
        "      return None\n",
        "    elif 'K' in num_string:\n",
        "        number = float(num_string.replace('K', '')) * 1000\n",
        "    elif 'M' in num_string:\n",
        "        number = float(num_string.replace('M', '')) * 1000000\n",
        "    else:\n",
        "        number = float(num_string.replace('$', '').replace(',', ''))\n",
        "    return number\n",
        "  except Exception as ex:\n",
        "    #print(f\"Could not interpret value {num_string}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "print(convert_numbers('$14,300,000'))\n",
        "print(convert_numbers('3.3K'))\n",
        "print(convert_numbers('2.6M'))\n",
        "print(convert_numbers('2.6M'))\n",
        "print(convert_numbers('350000000.0'))\n",
        "print(convert_numbers('87'))\n",
        "print(convert_numbers('87.00'))\n",
        "print(convert_numbers(None))"
      ],
      "metadata": {
        "id": "K-TYX7b5lewn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "  if not text:\n",
        "    return 0\n",
        "  else:\n",
        "    words = text.split()\n",
        "    return len(words)\n",
        "\n",
        "print(count_words(\"Puss in Boots: The Last Wish\"))\n",
        "print(count_words(\"X\"))\n",
        "print(count_words(None))\n",
        "print(count_words(\"\"))"
      ],
      "metadata": {
        "id": "uoyoYKB4zHiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Rating to Rating Category"
      ],
      "metadata": {
        "id": "2CmSbq0aHQQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rating_to_category(movie_rating):\n",
        "    rating_category = {\n",
        "        \"NC-17\": \"R\",\n",
        "        \"16+\": \"R\",\n",
        "        \"18+\": \"R\",\n",
        "        \"Approved\": \"G\",\n",
        "        \"G\": \"G\",\n",
        "        \"M\": \"PG-13\",\n",
        "        \"Not Rated\": \"Unrated\",\n",
        "        \"PG\": \"PG-13\",\n",
        "        \"PG-13\": \"PG-13\",\n",
        "        \"R\": \"R\",\n",
        "        \"TV-14\": \"PG-13\",\n",
        "        \"TV-G\": \"G\",\n",
        "        \"TV-MA\": \"R\",\n",
        "        \"TV-PG\": \"PG-13\",\n",
        "        \"TV-Y\": \"G\",\n",
        "        \"TV-Y7\": \"G\",\n",
        "        \"Unrated\": \"Unrated\"\n",
        "    }\n",
        "    return rating_category.get(movie_rating, \"Unrated\")\n",
        "\n",
        "print(rating_to_category(\"M\"))\n",
        "print(rating_to_category(\"TV-Y\"))\n",
        "print(rating_to_category(\"\"))\n",
        "print(rating_to_category(None))\n",
        "print(rating_to_category(\"BadValue\"))"
      ],
      "metadata": {
        "id": "RZ6jHr_x3-zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Genere to Genere Category"
      ],
      "metadata": {
        "id": "DP_RMJj4HUe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def genre_list_to_catg(genre_list):\n",
        "  genre_dict = {\"genre__count\":0}\n",
        "  if type(genre_list) == str:\n",
        "    g_list = genre_list.strip().split(',')\n",
        "    genre_dict[\"genre__count\"] = len(g_list)\n",
        "  \n",
        "    for g in g_list:\n",
        "      genre_dict[f\"genere_{g.strip().lower()}\"] = True\n",
        "\n",
        "  return genre_dict\n",
        "\n",
        "print(genre_list_to_catg(\"Action, \"))\n",
        "print(genre_list_to_catg(\"Action, adventure, Fantasy\"))\n",
        "print(genre_list_to_catg(\"Biography, Comedy, Music\"))\n",
        "print(genre_list_to_catg(None))\n",
        "print(genre_list_to_catg(\"\"))"
      ],
      "metadata": {
        "id": "xuxlnV8P3t8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Language to Language Category"
      ],
      "metadata": {
        "id": "TLkpQsReHXdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def language_list_to_catg(language_list):\n",
        "  language_dict = {}\n",
        "  if type(language_list)==str:\n",
        "    l_list = language_list.strip().split(',')\n",
        "    language_dict[\"language__count\"] = len(l_list)\n",
        "\n",
        "    for l in l_list:\n",
        "        language_dict[f\"language_{l.strip().lower()}\"] = True\n",
        "  else:\n",
        "    language_dict[f\"language_english\"] = True\n",
        "    language_dict[\"language__count\"] = 1\n",
        "\n",
        "  return language_dict\n",
        "\n",
        "print(language_list_to_catg(\"English\"))\n",
        "print(language_list_to_catg(\"English,Mandarin,Cantonese\"))\n",
        "print(language_list_to_catg(None))\n",
        "print(language_list_to_catg(\"\"))"
      ],
      "metadata": {
        "id": "WFTvjyZl89Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Extract Crew Stats"
      ],
      "metadata": {
        "id": "FXIoXJkDHaxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_artist_stats(row,movie_id):\n",
        "\n",
        "  artist_stats_dict = {}\n",
        "\n",
        "  movie_name = row['movie_name']\n",
        "\n",
        "  artist_cols = ['Star_1_imdb_id','Star_2_imdb_id','Star_3_imdb_id','Director_1_imdb_id','Director_2_imdb_id','Director_3_imdb_id','Writer_1_imdb_id','Writer_2_imdb_id','Writer_3_imdb_id']\n",
        "\n",
        "  #info to extract:\n",
        "  main_crew_count = 0\n",
        "  crew_age_sum = 0\n",
        "  crew_age_avg = 0\n",
        "  crew_age_missing = 0\n",
        "  crew_female_count = 0\n",
        "  crew_nonbinary_count = 0\n",
        "  crew_lgbt_count = 0\n",
        "  crew_prestige_wins = 0\n",
        "  crew_prestige_nominations = 0\n",
        "  crew_awards_wins = 0\n",
        "  crew_awards_nominations = 0\n",
        "\n",
        "  for artist in artist_cols:\n",
        "    try:\n",
        "      artist_imdb_id = row.get(artist)\n",
        "      if type(artist_imdb_id) == str:\n",
        "        main_crew_count += 1\n",
        "\n",
        "        artist_data = artists_list.get(artist_imdb_id)\n",
        "        artist_name = artist_data.get('artist_name')\n",
        "        artist_gender = artist_data.get('artist_gender')\n",
        "        \n",
        "        if artist_gender==\"Female\":\n",
        "          crew_female_count+=1\n",
        "        elif artist_gender==\"NonBinary\":\n",
        "          crew_nonbinary_count+=1\n",
        "\n",
        "        artist_lgbt = artist_data.get('is_openly_lgbt')\n",
        "        if artist_lgbt:\n",
        "          crew_lgbt_count += 1\n",
        "\n",
        "        age = artist_data.get('artist_age')\n",
        "        #print(artist_data)\n",
        "        #print(artist_imdb_id,artist_name,age,artist_data['artist_age'])\n",
        "        if not age:\n",
        "          crew_age_missing += 1\n",
        "        else:\n",
        "          crew_age_sum += age\n",
        "\n",
        "        crew_prestige_wins += artist_data.get('awards_prestige_wins')\n",
        "        crew_prestige_nominations += artist_data.get('awards_prestige_nominations')\n",
        "        crew_awards_wins += artist_data.get('awards_other_won')\n",
        "        crew_awards_nominations += artist_data.get('awards_other_nominations')\n",
        "    except Exception as e:\n",
        "      print(f\"Failed extracting data for artist: {artist} - {artist_data.get('artist_name')}. \\nmovie_name: {movie_name}({movie_id}).\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "  if crew_age_sum: # Ag age is the sum age divided by the number of collected ages (total minus missing)\n",
        "    crew_age_avg = crew_age_sum/(main_crew_count-crew_age_missing)\n",
        "  else:\n",
        "    print(f'None of the crew for movie {movie_name}({movie_id} had their age listed in their bio page.')\n",
        "    crew_age_avg = None\n",
        "\n",
        "  artist_stats_dict['main_crew_count'] = main_crew_count\n",
        "  artist_stats_dict['crew_age_avg'] = crew_age_avg\n",
        "  artist_stats_dict['crew_age_missing'] = crew_age_missing\n",
        "  artist_stats_dict['crew_female_count'] = crew_female_count\n",
        "  artist_stats_dict['crew_nonbinary_count'] = crew_nonbinary_count\n",
        "  artist_stats_dict['crew_lgbt_count'] = crew_lgbt_count\n",
        "  artist_stats_dict['crew_prestige_wins'] = crew_prestige_wins\n",
        "  artist_stats_dict['crew_prestige_nominations'] = crew_prestige_nominations\n",
        "  artist_stats_dict['crew_awards_wins'] = crew_awards_wins\n",
        "  artist_stats_dict['crew_awards_nominations'] = crew_awards_nominations\n",
        "  return artist_stats_dict\n",
        "\n",
        "extract_artist_stats(row,\"tt22061140\")"
      ],
      "metadata": {
        "id": "qD_ene6u_UPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Function: Build IMDB Dataset"
      ],
      "metadata": {
        "id": "ziMgGb3eICYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_imdb_movie_dataset(movie_id,total_movie_dataset):\n",
        "\n",
        "  row = total_movie_dataset[movie_id]\n",
        "\n",
        "  amount_cols = ['budget_usd','runtime_min']\n",
        "\n",
        "  imdb_movie = {\"_finshed_successfully\":False}\n",
        "\n",
        "  for col in amount_cols:\n",
        "    imdb_movie[col] = convert_numbers(str(row.get(col)))\n",
        "\n",
        "  imdb_movie['movie_name'] = row.get('movie_name')\n",
        "  imdb_movie['title_length'] = count_words(row.get('movie_name'))\n",
        "  imdb_movie['movie_desc_length'] = count_words(row.get('movie_description'))\n",
        "  imdb_movie['rating_catg'] = rating_to_category(row.get('movie_rating'))\n",
        "  imdb_movie['movie_year'] = 2022 if row.get('movie_year') is None else row.get('movie_year')\n",
        "  imdb_movie['release_year'] = 2022 if row.get('release_year') is None else row.get('release_year')\n",
        "  imdb_movie['release_month'] = row.get('release_month') \n",
        "  imdb_movie['release_country'] = \"United States\" if row.get('release_country') is None else row.get('release_country')\n",
        "  imdb_movie['budget_currency'] = \"USD\" if row.get('budget_currency') is None else row.get('budget_currency')\n",
        "\n",
        "  # cast count:\n",
        "  for k in row.keys():\n",
        "    if 'cast_count' in k:\n",
        "      imdb_movie[k] = 0 if row[k] is None else row[k] \n",
        "\n",
        "  # genere:\n",
        "  movie_genre_dict = genre_list_to_catg(row.get('movie_genere'))\n",
        "  imdb_movie.update(movie_genre_dict)\n",
        "\n",
        "  # language:\n",
        "  languages_dict = language_list_to_catg(row.get('languages'))\n",
        "  imdb_movie.update(languages_dict)\n",
        "\n",
        "  # Get dependent columns:\n",
        "  imdb_movie['pred_metascore'] = row.get('movie_metascore')\n",
        "  imdb_movie['pred_user_rating'] = row.get('user_rating')\n",
        "  imdb_movie['pred_user_review_count'] = convert_numbers(str(row.get('user_reviews_count')))\n",
        "  imdb_movie['pred_critic_review_count'] = convert_numbers(str(row.get('critic_reviews_count')))\n",
        "  imdb_movie['pred_total_vote_count'] = convert_numbers(str(row.get('movie_vote_num')))\n",
        "  imdb_movie['pred_gross_worldwide'] = convert_numbers(str(row.get('gross_worldwide')))\n",
        "  imdb_movie['pred_gross_us_canada'] = convert_numbers(str(row.get('gross_us_canada')))\n",
        "  imdb_movie['pred_opening_weekend_us_canada'] = convert_numbers(str(row.get('opening_weekend_us_canada')))\n",
        "\n",
        "  # Get crew stats:\n",
        "  crew_stats = extract_artist_stats(row,movie_id)\n",
        "  imdb_movie[\"_finshed_successfully\"] = True\n",
        "  imdb_movie.update(crew_stats)\n",
        "\n",
        "  #print(row)\n",
        "  return imdb_movie\n",
        "\n",
        "#build_imdb_movie_dataset(\"tt16379898\",total_movie_dataset)"
      ],
      "metadata": {
        "id": "-XnCDaNOothJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/imdb_movie_dataset_raw.csv\"\n",
        "if os.path.exists(imdb_movie_dataset_path):\n",
        "  imdb_movie_raw_dataset = pd.read_csv(imdb_movie_dataset_path, index_col=['movie_id'])\n",
        "  imdb_movie_raw_dict = imdb_movie_raw_dataset.T.to_dict()\n",
        "  \n",
        "else:\n",
        "  imdb_movie_raw_dict = {}\n",
        "  imdb_movie_raw_dataset = pd.DataFrame(imdb_movie_raw_dict)\n",
        "\n",
        "print(f\"imdb_movie_raw_dict contains {len(imdb_movie_raw_dict)} records\")\n",
        "imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "P_-nHFhwDAjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cursor: Finalize Dataset"
      ],
      "metadata": {
        "id": "enzukGWpnRXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_processed = 0\n",
        "movies_skipped = 0\n",
        "movie_count = 0\n",
        "for i, row in movie_dataset.iterrows():\n",
        "  movie_count += 1\n",
        "  try:\n",
        "    imdb_movie_record = {}\n",
        "    movie_id = row['movie_id']\n",
        "    if movie_id in imdb_movie_raw_dict.keys() and imdb_movie_raw_dict[movie_id]['_finshed_successfully']==True:\n",
        "      imdb_movie_record = imdb_movie_raw_dict[movie_id]\n",
        "      movies_skipped += 1\n",
        "    else:\n",
        "      imdb_movie_record = build_imdb_movie_dataset(movie_id,total_movie_dataset)\n",
        "\n",
        "\n",
        "    imdb_movie_raw_dict[movie_id] = imdb_movie_record\n",
        "  except Exception as e:\n",
        "    print(f\"Failed building finished data for movie: {movie_id}. \\nRaw Data: {row}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    imdb_movie_record['_finshed_successfully'] = False;\n",
        "\n",
        " \n",
        "imdb_movie_raw_dataset = pd.DataFrame(imdb_movie_raw_dict).T\n",
        "print(f\"\\n\\nFinished process. Total: {movie_count}. movies_processed:{movies_processed}. movies_skipped:{movies_skipped}\")\n",
        "imdb_movie_raw_dataset.to_csv(imdb_movie_dataset_path, index=True, index_label=\"movie_id\")"
      ],
      "metadata": {
        "id": "v5sdDPzVj1ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "bWJBNAeMk_yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all nan values to 0s:\n",
        "\n",
        "for col in imdb_movie_raw_dataset.columns:\n",
        "    # Check if the column name starts with 'cast_count'\n",
        "    if col.startswith('cast_count_'):\n",
        "        # Replace NaN values with 0\n",
        "        imdb_movie_raw_dataset[col] = imdb_movie_raw_dataset[col].fillna(0)\n",
        "    elif col.startswith('language_') or col.startswith('genere_'):\n",
        "      # Replace NaN values with False\n",
        "        imdb_movie_raw_dataset[col] = imdb_movie_raw_dataset[col].fillna(False)\n",
        "\n",
        "\n",
        "\n",
        "imdb_movie_raw_dataset.to_csv(imdb_movie_dataset_path, index=True, index_label=\"movie_id\")\n",
        "imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "k1UV4kU4Eu6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Future Movies:"
      ],
      "metadata": {
        "id": "vAt_c5eKUeDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2023-05-01'\n",
        "end_date = '2023-06-30'\n",
        "\n",
        "def get_50_unreleased_movie_batch(start_point, start_date = \"2022-01-01\", end_date = \"2022-12-31\", print_results = False):\n",
        "  movie_search_url_50_batch = f\"{base_url}/search/title/?title_type=feature&release_date={start_date},{end_date}&countries=us&languages=en&start={start_point}&ref_=adv_nxt\"\n",
        "  \n",
        "  search_page = requests.get(f'{movie_search_url_50_batch}', headers=headers, timeout=10)\n",
        "  search_page_soup = BeautifulSoup(search_page.text, 'html.parser')\n",
        "  list_of_50_movies_soup = search_page_soup.find_all('div',{'class':'lister-item mode-advanced'})\n",
        "\n",
        "  max_num_of_results = search_page_soup.find('div',{'class':'desc'}).find('span').text.split(' ')[2].replace(\",\", \"\")\n",
        "  max_num_of_results = int(max_num_of_results)\n",
        "  if print_results: print(f\"Start point: {start_point}. start_date: {start_date}. end_date: {end_date}. \\nTotal Movies: {max_num_of_results} \\nsearch url: {movie_search_url_50_batch}\")\n",
        "\n",
        "  #print(f\"max_num_of_results: {max_num_of_results}\")\n",
        "  return(list_of_50_movies_soup,max_num_of_results)\n",
        "\n",
        "list_of_50_future_movies_soup,max_num_of_results = get_50_unreleased_movie_batch(start_point = 1, start_date = start_date, end_date = end_date, print_results = True)"
      ],
      "metadata": {
        "id": "AZGpYJs8Vtz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_movies_dict_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/future_movies_dataset.csv\"\n",
        "if os.path.exists(future_movies_dict_path):\n",
        "  future_movies_df = pd.read_csv(future_movies_dict_path)\n",
        "  future_movies_dict = future_movies_df.set_index('movie_id').T.to_dict()\n",
        "  \n",
        "else:\n",
        "  future_movies_dict = {}\n",
        "  future_movies_df = pd.DataFrame(future_movies_dict)\n",
        "\n",
        "print(f\"future_movies_dict contains {len(future_movies_dict)} records\")\n",
        "future_movies_df.head(3)"
      ],
      "metadata": {
        "id": "9Y9nzNxGWoCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Movies - Collect raw movie data"
      ],
      "metadata": {
        "id": "lJ1V-rnHoxVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_point = 1 # Start from movie #1-50\n",
        "\n",
        "basic_data_collected = 0\n",
        "basic_data_skipped = 0\n",
        "extended_data_collected = 0\n",
        "extended_data_skipped = 0\n",
        "\n",
        "count = 1\n",
        "while start_point < max_num_of_results-50:\n",
        "\n",
        "  list_of_50_future_movies_soup,max_num_of_results = get_50_unreleased_movie_batch(start_point = start_point, start_date = start_date, end_date = end_date, print_results = False)\n",
        "  if count==1: print(f\"Starting run collecting movies. Total of {max_num_of_results} movies to be collected.\")\n",
        "\n",
        "  for i,movie in enumerate(list_of_50_future_movies_soup):\n",
        "    future_movie_data = {'__SuccsefullyCollectBasicDetails':False, '__SuccsefullyCollectExtandedDetails':False}\n",
        "\n",
        "    basic_data = get_basic_details(movie)\n",
        "    movie_id = basic_data['movie_id']\n",
        "\n",
        "    try:\n",
        "      if movie_id in future_movies_dict.keys():\n",
        "        future_movie_data = future_movies_dict[movie_id]\n",
        "\n",
        "      if future_movie_data['__SuccsefullyCollectBasicDetails']==True:\n",
        "        basic_data_skipped += 1\n",
        "      else:\n",
        "        basic_data_collected += 1\n",
        "        future_movie_data.update(basic_data)\n",
        "\n",
        "      if future_movie_data['__SuccsefullyCollectExtandedDetails']==True:\n",
        "        extended_data_skipped += 1\n",
        "      else:\n",
        "        extended_data_collected += 1\n",
        "        extended_data = get_extended_datails(basic_data['movie_page_url'],basic_data['movie_name'])\n",
        "        future_movie_data.update(extended_data)\n",
        "\n",
        "        sleep(0.1)\n",
        "    except Exception as e:\n",
        "      print(f\"Failed running cursor for movie: {movie_id}. \\nUrl: {basic_data['movie_page_url']}.\\n Error:\\n{e}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "    future_movies_dict[movie_id] = future_movie_data\n",
        "    count+= 1\n",
        "\n",
        "    if (count%30 == 0):\n",
        "      print(f\"\\nRun number: {count}. basic_data_collected: {basic_data_collected}. extended_data_collected: {extended_data_collected}. basic_data_skipped: {basic_data_skipped}. extended_data_skipped: {extended_data_skipped}\")\n",
        "\n",
        "\n",
        "  future_movies_df = pd.DataFrame(future_movies_dict).T\n",
        "  future_movies_df.to_csv(future_movies_dict_path, index=True, index_label=\"movie_id\")\n",
        "\n",
        "  start_point += 50\n",
        "\n",
        "future_movies_df = pd.DataFrame(future_movies_dict).T\n",
        "future_movies_df.to_csv(future_movies_dict_path, index=True, index_label=\"movie_id\")\n",
        "print(f\"\\nRun number: {count}. \\nbasic_data_collected: {basic_data_collected}. \\nextended_data_collected: {extended_data_collected}. \\nbasic_data_skipped: {basic_data_skipped}. \\nextended_data_skipped: {extended_data_skipped}\\n\")"
      ],
      "metadata": {
        "id": "4TCLpMd7UiVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Movies - Update unmapped artists"
      ],
      "metadata": {
        "id": "c5i_mlPuo120"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_cols = [col for col in future_movies_df.columns if \"imdb_id\" in col]\n",
        "\n",
        "artists_skipped = 0\n",
        "artists_collected = 0\n",
        "artist_count = 1\n",
        "for i, row in future_movies_df.iterrows():\n",
        "  for col_name in artist_cols:\n",
        "    artist_dict = {'artist_collected':False}\n",
        "    artist_imdb_id = row[col_name]\n",
        "    if type(artist_imdb_id) != float:\n",
        "      if artist_imdb_id in artists_list.keys() and artists_list[artist_imdb_id]['artist_collected']==True:\n",
        "        artist_dict = artists_list[artist_imdb_id]\n",
        "        artist_dict['artist_collected']=True\n",
        "        artists_skipped += 1\n",
        "      else:\n",
        "        artist_output = extract_artist_info(artist_imdb_id,col_name)\n",
        "        if artist_output!=None:\n",
        "          artist_dict.update(artist_output)\n",
        "          artist_dict['artist_collected']=True\n",
        "        artists_collected += 1 \n",
        "        sleep(0.1)\n",
        "\n",
        "      artists_list[artist_imdb_id] = artist_dict\n",
        "      artist_count += 1\n",
        "      if artist_count%200 == 0:\n",
        "        artist_dataset = pd.DataFrame(artists_list).T\n",
        "        artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "        print(f\"\\nSaving progress. Run {artist_count} for movie {i}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")\n",
        "\n",
        "artist_dataset = pd.DataFrame(artists_list).T\n",
        "artist_dataset.to_csv(artists_dataset_path, index=True, index_label=\"artist_imdb_id\")\n",
        "print(f\"\\n\\nFinished process. Total: {artist_count}. artists_collected:{artists_collected}. artists_skipped:{artists_skipped}\")"
      ],
      "metadata": {
        "id": "lf6DRuyilgwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Movies - Finalize dataset"
      ],
      "metadata": {
        "id": "ebBRzEqto477"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future_imdb_movie_dataset_path = \"/content/drive/My Drive/Harvard HW/Course 4 - Final Project/future_imdb_movie_dataset_raw.csv\"\n",
        "if os.path.exists(future_imdb_movie_dataset_path):\n",
        "  future_imdb_movie_raw_dataset = pd.read_csv(future_imdb_movie_dataset_path, index_col=['movie_id'])\n",
        "  future_imdb_movie_raw_dict = future_imdb_movie_raw_dataset.T.to_dict()\n",
        "  \n",
        "else:\n",
        "  future_imdb_movie_raw_dict = {}\n",
        "  future_imdb_movie_raw_dataset = pd.DataFrame(future_imdb_movie_raw_dict)\n",
        "\n",
        "print(f\"imdb_movie_raw_dict contains {len(future_imdb_movie_raw_dict)} records\")\n",
        "future_imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "9xluh6jNp2zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_processed = 0\n",
        "movies_skipped = 0\n",
        "movie_count = 0\n",
        "for i, row in future_movies_df.iterrows():\n",
        "  movie_count += 1\n",
        "  try:\n",
        "    imdb_movie_record = {}\n",
        "    movie_id = row['movie_id']\n",
        "    if movie_id in future_imdb_movie_raw_dict.keys() and future_imdb_movie_raw_dict[movie_id]['_finshed_successfully']==True:\n",
        "      imdb_movie_record = future_imdb_movie_raw_dict[movie_id]\n",
        "      movies_skipped += 1\n",
        "    else:\n",
        "      imdb_movie_record = build_imdb_movie_dataset(movie_id,future_movies_dict)\n",
        "\n",
        "\n",
        "    future_imdb_movie_raw_dict[movie_id] = imdb_movie_record\n",
        "  except Exception as e:\n",
        "    print(f\"Failed building finished data for movie: {movie_id}. \\nRaw Data: {row}.\\n Error:\\n{e}\")\n",
        "    traceback.print_exc()\n",
        "    imdb_movie_record['_finshed_successfully'] = False;\n",
        "\n",
        " \n",
        "future_imdb_movie_raw_dataset = pd.DataFrame(future_imdb_movie_raw_dict).T\n",
        "print(f\"\\n\\nFinished process. Total: {movie_count}. movies_processed:{movies_processed}. movies_skipped:{movies_skipped}\")\n",
        "future_imdb_movie_raw_dataset.to_csv(future_imdb_movie_dataset_path, index=True, index_label=\"movie_id\")"
      ],
      "metadata": {
        "id": "SZJL5hDAoRch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_imdb_movie_raw_dataset.head(3)"
      ],
      "metadata": {
        "id": "WILFA9BFzFKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}